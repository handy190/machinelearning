{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import keras\n",
    "print(keras.__version__)\n",
    "\n",
    "from math import nan\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from keras_contrib.layers import CRF\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dframe = pd.read_csv(\"ner_small.csv\", encoding = \"ISO-8859-1\", error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=dframe.drop(['Unnamed: 0', 'lemma', 'next-lemma', 'next-next-lemma', 'next-next-pos',\n",
    "       'next-next-shape', 'next-next-word', 'next-pos', 'next-shape',\n",
    "       'next-word', 'prev-iob', 'prev-lemma', 'prev-pos',\n",
    "       'prev-prev-iob', 'prev-prev-lemma', 'prev-prev-pos', 'prev-prev-shape',\n",
    "       'prev-prev-word', 'prev-shape', 'prev-word',\"pos\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15591 entries, 0 to 15590\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   sentence_idx  15591 non-null  int64 \n",
      " 1   shape         15591 non-null  object\n",
      " 2   word          15591 non-null  object\n",
      " 3   tag           15591 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 487.3+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_idx</th>\n",
       "      <th>shape</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>marched</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_idx        shape           word tag\n",
       "0             1  capitalized      Thousands   O\n",
       "1             1    lowercase             of   O\n",
       "2             1    lowercase  demonstrators   O\n",
       "3             1    lowercase           have   O\n",
       "4             1    lowercase        marched   O"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=dataset.drop(['shape'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_idx</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>marched</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_idx           word tag\n",
       "0             1      Thousands   O\n",
       "1             1             of   O\n",
       "2             1  demonstrators   O\n",
       "3             1           have   O\n",
       "4             1        marched   O"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, dataset):\n",
    "        self.n_sent = 1\n",
    "        self.dataset = dataset\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, t) for w,t in zip(s[\"word\"].values.tolist(),\n",
    "                                                        s[\"tag\"].values.tolist())]\n",
    "        self.grouped = self.dataset.groupby(\"sentence_idx\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "getter = SentenceGetter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'O'), ('party', 'O'), ('is', 'O'), ('divided', 'O'), ('over', 'O'), ('Britain', 'B-gpe'), (\"'s\", 'O'), ('participation', 'O'), ('in', 'O'), ('the', 'O'), ('Iraq', 'B-geo'), ('conflict', 'O'), ('and', 'O'), ('the', 'O'), ('continued', 'O'), ('deployment', 'O'), ('of', 'O'), ('8,500', 'O'), ('British', 'B-gpe'), ('troops', 'O'), ('in', 'O'), ('that', 'O'), ('country', 'O'), ('.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "print(sentences[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length: 62\n"
     ]
    }
   ],
   "source": [
    "maxlen = max([len(s) for s in sentences])\n",
    "print ('Maximum sequence length:', maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(set(dataset[\"word\"].values))\n",
    "words.append(\"ENDPAD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3691"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_words = len(words); n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-tim', 'I-eve', 'B-per', 'B-geo', 'B-org', 'B-tim', 'I-geo', 'O', 'I-org', 'I-per', 'I-nat', 'I-art', 'B-nat', 'I-gpe', 'B-art', 'B-gpe', 'B-eve']\n"
     ]
    }
   ],
   "source": [
    "tags = []\n",
    "for tag in set(dataset[\"tag\"].values):\n",
    "    if tag is nan or isinstance(tag, float):\n",
    "        tags.append('unk')\n",
    "    else:\n",
    "        tags.append(tag)\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tags = len(tags); n_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from future.utils import iteritems\n",
    "word2idx = {w: i for i, w in enumerate(words)}\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}\n",
    "idx2tag = {v: k for k, v in iteritems(tag2idx)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "X = [[word2idx[w[0]] for w in s] for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(702,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pad_sequences(maxlen=140, sequences=X, padding=\"post\",value=n_words - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'O'), ('Pakistani', 'B-gpe'), ('military', 'O'), ('launched', 'O'), ('its', 'O'), ('offensive', 'O'), ('in', 'O'), ('Orakzai', 'B-geo'), ('to', 'O'), ('hunt', 'O'), ('Taliban', 'B-org'), ('insurgents', 'O'), ('.', 'O')]\n",
      "[7, 15, 7, 7, 7, 7, 7, 3, 7, 7, 4, 7, 7]\n"
     ]
    }
   ],
   "source": [
    "y_idx = [[tag2idx[w[1]] for w in s] for s in sentences]\n",
    "print(sentences[100])\n",
    "print(y_idx[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 15, 7, 7, 7, 7, 7, 3, 7, 7, 4, 7, 7]\n"
     ]
    }
   ],
   "source": [
    "y = pad_sequences(maxlen=140, sequences=y_idx, padding=\"post\", value=tag2idx[\"O\"])\n",
    "print(y_idx[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y = [to_categorical(i, num_classes=n_tags) for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(561, 140)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3058, 1201, 1811, 2013, 3213, 2521, 1626, 3550, 1651, 3104, 2339,\n",
       "        749,  660, 3078, 3550, 2521, 1596, 1180, 3524, 2521, 2506, 3550,\n",
       "       1772, 3549, 3047, 3550, 2821, 3488, 3079, 2354, 3058, 1979, 3690,\n",
       "       3690, 3690, 3690, 3690, 3690, 3690, 3690, 3690, 3690, 3690, 3690,\n",
       "       3690, 3690, 3690, 3690, 3690, 3690, 3690, 3690, 3690, 3690, 3690,\n",
       "       3690, 3690, 3690, 3690, 3690, 3690, 3690, 3690, 3690, 3690, 3690,\n",
       "       3690, 3690, 3690, 3690, 3690, 3690, 3690, 3690, 3690, 3690, 3690,\n",
       "       3690, 3690, 3690, 3690, 3690, 3690, 3690, 3690, 3690, 3690, 3690,\n",
       "       3690, 3690, 3690, 3690, 3690, 3690, 3690, 3690, 3690, 3690, 3690,\n",
       "       3690, 3690, 3690, 3690, 3690, 3690, 3690, 3690, 3690, 3690, 3690,\n",
       "       3690, 3690, 3690, 3690, 3690, 3690, 3690, 3690, 3690, 3690, 3690,\n",
       "       3690, 3690, 3690, 3690, 3690, 3690, 3690, 3690, 3690, 3690, 3690,\n",
       "       3690, 3690, 3690, 3690, 3690, 3690, 3690, 3690])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " (140, 17))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1],y_train[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "import keras as k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(140,))\n",
    "word_embedding_size = 300\n",
    "model = Embedding(input_dim=n_words, output_dim=word_embedding_size, input_length=140)(input)\n",
    "model = Bidirectional(LSTM(units=word_embedding_size, \n",
    "                           return_sequences=True, \n",
    "                           dropout=0.5, \n",
    "                           recurrent_dropout=0.5, \n",
    "                           kernel_initializer=k.initializers.he_normal()))(model)\n",
    "model = LSTM(units=word_embedding_size * 2, \n",
    "             return_sequences=True, \n",
    "             dropout=0.5, \n",
    "             recurrent_dropout=0.5, \n",
    "             kernel_initializer=k.initializers.he_normal())(model)\n",
    "model = TimeDistributed(Dense(n_tags, activation=\"relu\"))(model)  # previously softmax output layer\n",
    "\n",
    "crf = CRF(n_tags)  # CRF layer\n",
    "out = crf(model)  # output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input, out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ProgramData\\Anaconda3\\envs\\env_nlp_basic_py36\\lib\\site-packages\\keras_contrib\\layers\\crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
      "  warnings.warn('CRF.loss_function is deprecated '\n",
      "F:\\ProgramData\\Anaconda3\\envs\\env_nlp_basic_py36\\lib\\site-packages\\keras_contrib\\layers\\crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
      "  warnings.warn('CRF.accuracy is deprecated and it '\n"
     ]
    }
   ],
   "source": [
    "adam = k.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999)\n",
    "#model.compile(optimizer=adam, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.compile(optimizer=adam, loss=crf.loss_function, metrics=[crf.accuracy, 'accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ProgramData\\Anaconda3\\envs\\env_nlp_basic_py36\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 448 samples, validate on 113 samples\n",
      "Epoch 1/3\n",
      "448/448 [==============================] - 41s 90ms/step - loss: 2.6341 - crf_viterbi_accuracy: 0.1420 - accuracy: 2.0727e-04 - val_loss: 1.9715 - val_crf_viterbi_accuracy: 0.8456 - val_accuracy: 0.8456\n",
      "Epoch 2/3\n",
      "448/448 [==============================] - 37s 83ms/step - loss: 1.8518 - crf_viterbi_accuracy: 0.8530 - accuracy: 2.0727e-04 - val_loss: 0.8286 - val_crf_viterbi_accuracy: 0.9429 - val_accuracy: 0.9429\n",
      "Epoch 3/3\n",
      "448/448 [==============================] - 45s 100ms/step - loss: 0.8480 - crf_viterbi_accuracy: 0.9455 - accuracy: 2.0727e-04 - val_loss: 0.3096 - val_crf_viterbi_accuracy: 0.9765 - val_accuracy: 0.9765\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, np.array(y_train), batch_size=256, epochs=3, validation_split=0.2, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
      "  7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
      "  7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
      "  7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]]\n"
     ]
    }
   ],
   "source": [
    "p = model.predict(np.array([X_test[0]]))\n",
    "p = np.argmax(p, axis=-1)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7  7 15  7  7  7  7  7  3  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7]\n",
      "Word          : (True ): Pred\n",
      "However       : (O    ): O\n",
      ",             : (O    ): O\n",
      "U.S.          : (B-gpe): O\n",
      "forces        : (O    ): O\n",
      "have          : (O    ): O\n",
      "yet           : (O    ): O\n",
      "to            : (O    ): O\n",
      "enter         : (O    ): O\n",
      "Somalia       : (B-geo): O\n",
      ",             : (O    ): O\n",
      "which         : (O    ): O\n",
      "has           : (O    ): O\n",
      "been          : (O    ): O\n",
      "without       : (O    ): O\n",
      "a             : (O    ): O\n",
      "functioning   : (O    ): O\n",
      "central       : (O    ): O\n",
      "government    : (O    ): O\n",
      "for           : (O    ): O\n",
      "more          : (O    ): O\n",
      "than          : (O    ): O\n",
      "10            : (O    ): O\n",
      "years         : (O    ): O\n",
      ".             : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n",
      "ENDPAD        : (O    ): O\n"
     ]
    }
   ],
   "source": [
    "gt = np.argmax(y_test[0], axis=-1)\n",
    "print(gt)\n",
    "print(\"{:14}: ({:5}): {}\".format(\"Word\", \"True\", \"Pred\"))\n",
    "for idx, (w,pred) in enumerate(zip(X_test[0],p[0])):\n",
    "    #\n",
    "    print(\"{:14}: ({:5}): {}\".format(words[w],idx2tag[gt[idx]],tags[pred]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
