{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# create the training & test sets, skipping the header row with [1:]\n",
    "dataset = pd.read_csv(\"../../tmp/train.csv\")\n",
    "target = dataset[[0]].values.ravel()\n",
    "train = dataset.iloc[:,1:].values\n",
    "test = pd.read_csv(\"../../tmp/test.csv\").values\n",
    "\n",
    "x_test = test.reshape((len(test),28*28))\n",
    "x_train = train.reshape((len(train),28*28))[0:40000]\n",
    "y_train = target[0:40000]\n",
    "\n",
    "x_valid = train.reshape((len(train),28*28))[40000:]\n",
    "y_valid = target[40000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (40000, 784)\n",
      "y_train shape: (40000,)\n",
      "x_test shape: (28000, 784)\n",
      "x_valid shape: (2000, 784)\n",
      "y_valid shape: (2000,)\n"
     ]
    }
   ],
   "source": [
    "# check data\n",
    "print('x_train shape: {0}'.format(x_train.shape))\n",
    "print('y_train shape: {0}'.format(y_train.shape))\n",
    "print('x_test shape: {0}'.format(x_test.shape))\n",
    "\n",
    "print('x_valid shape: {0}'.format(x_valid.shape))\n",
    "print('y_valid shape: {0}'.format(y_valid.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.106325\tval-merror:0.144000\n",
      "[1]\ttrain-merror:0.069200\tval-merror:0.116000\n",
      "[2]\ttrain-merror:0.057600\tval-merror:0.094500\n",
      "[3]\ttrain-merror:0.051100\tval-merror:0.091000\n",
      "[4]\ttrain-merror:0.046700\tval-merror:0.083500\n",
      "[5]\ttrain-merror:0.045050\tval-merror:0.080000\n",
      "[6]\ttrain-merror:0.043475\tval-merror:0.081000\n",
      "[7]\ttrain-merror:0.041900\tval-merror:0.076500\n",
      "[8]\ttrain-merror:0.040950\tval-merror:0.074000\n",
      "[9]\ttrain-merror:0.040850\tval-merror:0.074000\n",
      "[10]\ttrain-merror:0.039950\tval-merror:0.071500\n",
      "[11]\ttrain-merror:0.039100\tval-merror:0.071500\n",
      "[12]\ttrain-merror:0.038500\tval-merror:0.069500\n",
      "[13]\ttrain-merror:0.038425\tval-merror:0.069500\n",
      "[14]\ttrain-merror:0.037775\tval-merror:0.069000\n",
      "[15]\ttrain-merror:0.037475\tval-merror:0.071000\n",
      "[16]\ttrain-merror:0.037225\tval-merror:0.069500\n",
      "[17]\ttrain-merror:0.036825\tval-merror:0.070500\n",
      "[18]\ttrain-merror:0.036575\tval-merror:0.073000\n",
      "[19]\ttrain-merror:0.036150\tval-merror:0.073000\n",
      "[20]\ttrain-merror:0.035825\tval-merror:0.073500\n",
      "[21]\ttrain-merror:0.035025\tval-merror:0.070500\n",
      "[22]\ttrain-merror:0.034850\tval-merror:0.070000\n",
      "[23]\ttrain-merror:0.034550\tval-merror:0.070000\n",
      "[24]\ttrain-merror:0.034225\tval-merror:0.069000\n",
      "[25]\ttrain-merror:0.033925\tval-merror:0.069500\n",
      "[26]\ttrain-merror:0.033500\tval-merror:0.069000\n",
      "[27]\ttrain-merror:0.033225\tval-merror:0.068500\n",
      "[28]\ttrain-merror:0.032875\tval-merror:0.068500\n",
      "[29]\ttrain-merror:0.032875\tval-merror:0.067500\n",
      "[30]\ttrain-merror:0.032700\tval-merror:0.066500\n",
      "[31]\ttrain-merror:0.032350\tval-merror:0.065500\n",
      "[32]\ttrain-merror:0.032225\tval-merror:0.067500\n",
      "[33]\ttrain-merror:0.031925\tval-merror:0.067500\n",
      "[34]\ttrain-merror:0.031700\tval-merror:0.066500\n",
      "[35]\ttrain-merror:0.031550\tval-merror:0.066000\n",
      "[36]\ttrain-merror:0.031000\tval-merror:0.065000\n",
      "[37]\ttrain-merror:0.031300\tval-merror:0.064500\n",
      "[38]\ttrain-merror:0.030950\tval-merror:0.064000\n",
      "[39]\ttrain-merror:0.030725\tval-merror:0.064000\n",
      "[40]\ttrain-merror:0.030575\tval-merror:0.064500\n",
      "[41]\ttrain-merror:0.030400\tval-merror:0.064500\n",
      "[42]\ttrain-merror:0.030200\tval-merror:0.064500\n",
      "[43]\ttrain-merror:0.030200\tval-merror:0.064000\n",
      "[44]\ttrain-merror:0.029925\tval-merror:0.065000\n",
      "[45]\ttrain-merror:0.029750\tval-merror:0.064500\n",
      "[46]\ttrain-merror:0.029475\tval-merror:0.063500\n",
      "[47]\ttrain-merror:0.029275\tval-merror:0.064000\n",
      "[48]\ttrain-merror:0.029250\tval-merror:0.065000\n",
      "[49]\ttrain-merror:0.029275\tval-merror:0.065000\n",
      "[50]\ttrain-merror:0.029250\tval-merror:0.064500\n",
      "[51]\ttrain-merror:0.029200\tval-merror:0.063500\n",
      "[52]\ttrain-merror:0.029225\tval-merror:0.063500\n",
      "[53]\ttrain-merror:0.029100\tval-merror:0.064000\n",
      "[54]\ttrain-merror:0.029150\tval-merror:0.063500\n",
      "[55]\ttrain-merror:0.028950\tval-merror:0.064000\n",
      "[56]\ttrain-merror:0.028725\tval-merror:0.063500\n",
      "[57]\ttrain-merror:0.028600\tval-merror:0.064000\n",
      "[58]\ttrain-merror:0.028450\tval-merror:0.063000\n",
      "[59]\ttrain-merror:0.028375\tval-merror:0.062000\n",
      "[60]\ttrain-merror:0.028000\tval-merror:0.061500\n",
      "[61]\ttrain-merror:0.027950\tval-merror:0.061500\n",
      "[62]\ttrain-merror:0.027875\tval-merror:0.062000\n",
      "[63]\ttrain-merror:0.027575\tval-merror:0.061000\n",
      "[64]\ttrain-merror:0.027575\tval-merror:0.062000\n",
      "[65]\ttrain-merror:0.027525\tval-merror:0.062000\n",
      "[66]\ttrain-merror:0.027300\tval-merror:0.062000\n",
      "[67]\ttrain-merror:0.027025\tval-merror:0.062000\n",
      "[68]\ttrain-merror:0.026750\tval-merror:0.062000\n",
      "[69]\ttrain-merror:0.026550\tval-merror:0.061500\n",
      "[70]\ttrain-merror:0.026625\tval-merror:0.063000\n",
      "[71]\ttrain-merror:0.026575\tval-merror:0.062000\n",
      "[72]\ttrain-merror:0.026350\tval-merror:0.062000\n",
      "[73]\ttrain-merror:0.026225\tval-merror:0.062000\n",
      "[74]\ttrain-merror:0.026275\tval-merror:0.061500\n",
      "[75]\ttrain-merror:0.026000\tval-merror:0.062000\n",
      "[76]\ttrain-merror:0.026000\tval-merror:0.061500\n",
      "[77]\ttrain-merror:0.025750\tval-merror:0.061000\n",
      "[78]\ttrain-merror:0.025750\tval-merror:0.061500\n",
      "[79]\ttrain-merror:0.025500\tval-merror:0.061500\n",
      "[80]\ttrain-merror:0.025625\tval-merror:0.061000\n",
      "[81]\ttrain-merror:0.025300\tval-merror:0.061000\n",
      "[82]\ttrain-merror:0.025300\tval-merror:0.060500\n",
      "[83]\ttrain-merror:0.025075\tval-merror:0.060000\n",
      "[84]\ttrain-merror:0.024975\tval-merror:0.060500\n",
      "[85]\ttrain-merror:0.025000\tval-merror:0.061500\n",
      "[86]\ttrain-merror:0.024800\tval-merror:0.061500\n",
      "[87]\ttrain-merror:0.024850\tval-merror:0.061500\n",
      "[88]\ttrain-merror:0.024825\tval-merror:0.061500\n",
      "[89]\ttrain-merror:0.024725\tval-merror:0.061000\n",
      "[90]\ttrain-merror:0.024650\tval-merror:0.060500\n",
      "[91]\ttrain-merror:0.024575\tval-merror:0.060000\n",
      "[92]\ttrain-merror:0.024475\tval-merror:0.060500\n",
      "[93]\ttrain-merror:0.024475\tval-merror:0.060000\n",
      "[94]\ttrain-merror:0.024375\tval-merror:0.059500\n",
      "[95]\ttrain-merror:0.024300\tval-merror:0.060500\n",
      "[96]\ttrain-merror:0.024100\tval-merror:0.060000\n",
      "[97]\ttrain-merror:0.024050\tval-merror:0.061000\n",
      "[98]\ttrain-merror:0.023950\tval-merror:0.060500\n",
      "[99]\ttrain-merror:0.023900\tval-merror:0.060500\n",
      "[100]\ttrain-merror:0.023850\tval-merror:0.059500\n",
      "[101]\ttrain-merror:0.023925\tval-merror:0.060000\n",
      "[102]\ttrain-merror:0.023950\tval-merror:0.060000\n",
      "[103]\ttrain-merror:0.023850\tval-merror:0.059000\n",
      "[104]\ttrain-merror:0.023775\tval-merror:0.058500\n",
      "[105]\ttrain-merror:0.023800\tval-merror:0.058500\n",
      "[106]\ttrain-merror:0.023725\tval-merror:0.058500\n",
      "[107]\ttrain-merror:0.023625\tval-merror:0.058500\n",
      "[108]\ttrain-merror:0.023625\tval-merror:0.058000\n",
      "[109]\ttrain-merror:0.023550\tval-merror:0.058000\n",
      "[110]\ttrain-merror:0.023500\tval-merror:0.058000\n",
      "[111]\ttrain-merror:0.023275\tval-merror:0.057500\n",
      "[112]\ttrain-merror:0.023325\tval-merror:0.057500\n",
      "[113]\ttrain-merror:0.023200\tval-merror:0.057500\n",
      "[114]\ttrain-merror:0.023325\tval-merror:0.057500\n",
      "[115]\ttrain-merror:0.023275\tval-merror:0.057500\n",
      "[116]\ttrain-merror:0.023250\tval-merror:0.057500\n",
      "[117]\ttrain-merror:0.023175\tval-merror:0.057000\n",
      "[118]\ttrain-merror:0.023000\tval-merror:0.057000\n",
      "[119]\ttrain-merror:0.022975\tval-merror:0.057000\n",
      "[120]\ttrain-merror:0.022800\tval-merror:0.057000\n",
      "[121]\ttrain-merror:0.022775\tval-merror:0.056500\n",
      "[122]\ttrain-merror:0.022750\tval-merror:0.057000\n",
      "[123]\ttrain-merror:0.022525\tval-merror:0.056500\n",
      "[124]\ttrain-merror:0.022575\tval-merror:0.056500\n",
      "[125]\ttrain-merror:0.022600\tval-merror:0.056000\n",
      "[126]\ttrain-merror:0.022575\tval-merror:0.055500\n",
      "[127]\ttrain-merror:0.022600\tval-merror:0.055500\n",
      "[128]\ttrain-merror:0.022450\tval-merror:0.056000\n",
      "[129]\ttrain-merror:0.022400\tval-merror:0.056000\n",
      "[130]\ttrain-merror:0.022350\tval-merror:0.056500\n",
      "[131]\ttrain-merror:0.022250\tval-merror:0.056500\n",
      "[132]\ttrain-merror:0.022200\tval-merror:0.057000\n",
      "[133]\ttrain-merror:0.022175\tval-merror:0.057000\n",
      "[134]\ttrain-merror:0.022075\tval-merror:0.056000\n",
      "[135]\ttrain-merror:0.021850\tval-merror:0.055500\n",
      "[136]\ttrain-merror:0.021875\tval-merror:0.056000\n",
      "[137]\ttrain-merror:0.021900\tval-merror:0.056000\n",
      "[138]\ttrain-merror:0.021775\tval-merror:0.056000\n",
      "[139]\ttrain-merror:0.021800\tval-merror:0.056000\n",
      "[140]\ttrain-merror:0.021725\tval-merror:0.056000\n",
      "[141]\ttrain-merror:0.021650\tval-merror:0.056000\n",
      "[142]\ttrain-merror:0.021500\tval-merror:0.056000\n",
      "[143]\ttrain-merror:0.021500\tval-merror:0.056000\n",
      "[144]\ttrain-merror:0.021450\tval-merror:0.056000\n",
      "[145]\ttrain-merror:0.021475\tval-merror:0.056000\n",
      "[146]\ttrain-merror:0.021450\tval-merror:0.056000\n",
      "[147]\ttrain-merror:0.021450\tval-merror:0.056000\n",
      "[148]\ttrain-merror:0.021425\tval-merror:0.056000\n",
      "[149]\ttrain-merror:0.021450\tval-merror:0.056000\n",
      "[150]\ttrain-merror:0.021375\tval-merror:0.056000\n",
      "[151]\ttrain-merror:0.021300\tval-merror:0.055500\n",
      "[152]\ttrain-merror:0.021275\tval-merror:0.055500\n",
      "[153]\ttrain-merror:0.021275\tval-merror:0.056000\n",
      "[154]\ttrain-merror:0.021300\tval-merror:0.056000\n",
      "[155]\ttrain-merror:0.021175\tval-merror:0.055500\n",
      "[156]\ttrain-merror:0.021175\tval-merror:0.055500\n",
      "[157]\ttrain-merror:0.021125\tval-merror:0.056000\n",
      "[158]\ttrain-merror:0.021100\tval-merror:0.056500\n",
      "[159]\ttrain-merror:0.021050\tval-merror:0.055500\n",
      "[160]\ttrain-merror:0.021075\tval-merror:0.056000\n",
      "[161]\ttrain-merror:0.020975\tval-merror:0.056000\n",
      "[162]\ttrain-merror:0.020975\tval-merror:0.055500\n",
      "[163]\ttrain-merror:0.020950\tval-merror:0.055500\n",
      "[164]\ttrain-merror:0.020900\tval-merror:0.055500\n",
      "[165]\ttrain-merror:0.020875\tval-merror:0.056500\n",
      "[166]\ttrain-merror:0.020750\tval-merror:0.056000\n",
      "[167]\ttrain-merror:0.020750\tval-merror:0.056000\n",
      "[168]\ttrain-merror:0.020625\tval-merror:0.055500\n",
      "[169]\ttrain-merror:0.020675\tval-merror:0.055500\n",
      "[170]\ttrain-merror:0.020625\tval-merror:0.056000\n",
      "[171]\ttrain-merror:0.020600\tval-merror:0.054500\n",
      "[172]\ttrain-merror:0.020525\tval-merror:0.054500\n",
      "[173]\ttrain-merror:0.020425\tval-merror:0.054500\n",
      "[174]\ttrain-merror:0.020425\tval-merror:0.054500\n",
      "[175]\ttrain-merror:0.020275\tval-merror:0.054500\n",
      "[176]\ttrain-merror:0.020225\tval-merror:0.055000\n",
      "[177]\ttrain-merror:0.020150\tval-merror:0.054500\n",
      "[178]\ttrain-merror:0.020175\tval-merror:0.054500\n",
      "[179]\ttrain-merror:0.020125\tval-merror:0.055000\n",
      "[180]\ttrain-merror:0.020075\tval-merror:0.054500\n",
      "[181]\ttrain-merror:0.020025\tval-merror:0.055000\n",
      "[182]\ttrain-merror:0.020000\tval-merror:0.054000\n",
      "[183]\ttrain-merror:0.019875\tval-merror:0.054000\n",
      "[184]\ttrain-merror:0.019850\tval-merror:0.054500\n",
      "[185]\ttrain-merror:0.019825\tval-merror:0.055000\n",
      "[186]\ttrain-merror:0.019725\tval-merror:0.055500\n",
      "[187]\ttrain-merror:0.019650\tval-merror:0.055000\n",
      "[188]\ttrain-merror:0.019675\tval-merror:0.054500\n",
      "[189]\ttrain-merror:0.019600\tval-merror:0.054500\n",
      "[190]\ttrain-merror:0.019575\tval-merror:0.054500\n",
      "[191]\ttrain-merror:0.019575\tval-merror:0.054500\n",
      "[192]\ttrain-merror:0.019575\tval-merror:0.054500\n",
      "[193]\ttrain-merror:0.019500\tval-merror:0.054500\n",
      "[194]\ttrain-merror:0.019450\tval-merror:0.055000\n",
      "[195]\ttrain-merror:0.019425\tval-merror:0.055000\n",
      "[196]\ttrain-merror:0.019475\tval-merror:0.055000\n",
      "[197]\ttrain-merror:0.019500\tval-merror:0.055000\n",
      "[198]\ttrain-merror:0.019525\tval-merror:0.054500\n",
      "[199]\ttrain-merror:0.019500\tval-merror:0.055000\n",
      "[200]\ttrain-merror:0.019500\tval-merror:0.054500\n",
      "[201]\ttrain-merror:0.019475\tval-merror:0.054000\n",
      "[202]\ttrain-merror:0.019425\tval-merror:0.054000\n",
      "[203]\ttrain-merror:0.019300\tval-merror:0.054000\n",
      "[204]\ttrain-merror:0.019275\tval-merror:0.054000\n",
      "[205]\ttrain-merror:0.019200\tval-merror:0.054000\n",
      "[206]\ttrain-merror:0.019150\tval-merror:0.053500\n",
      "[207]\ttrain-merror:0.019150\tval-merror:0.053500\n",
      "[208]\ttrain-merror:0.019150\tval-merror:0.054000\n",
      "[209]\ttrain-merror:0.019050\tval-merror:0.054500\n",
      "[210]\ttrain-merror:0.019000\tval-merror:0.053500\n",
      "[211]\ttrain-merror:0.019050\tval-merror:0.053500\n",
      "[212]\ttrain-merror:0.018950\tval-merror:0.053500\n",
      "[213]\ttrain-merror:0.018950\tval-merror:0.054000\n",
      "[214]\ttrain-merror:0.018775\tval-merror:0.053500\n",
      "[215]\ttrain-merror:0.018725\tval-merror:0.054000\n",
      "[216]\ttrain-merror:0.018825\tval-merror:0.053000\n",
      "[217]\ttrain-merror:0.018725\tval-merror:0.053000\n",
      "[218]\ttrain-merror:0.018750\tval-merror:0.053000\n",
      "[219]\ttrain-merror:0.018725\tval-merror:0.053000\n",
      "[220]\ttrain-merror:0.018675\tval-merror:0.053000\n",
      "[221]\ttrain-merror:0.018650\tval-merror:0.053000\n",
      "[222]\ttrain-merror:0.018575\tval-merror:0.053000\n",
      "[223]\ttrain-merror:0.018400\tval-merror:0.053500\n",
      "[224]\ttrain-merror:0.018500\tval-merror:0.053500\n",
      "[225]\ttrain-merror:0.018475\tval-merror:0.053000\n",
      "[226]\ttrain-merror:0.018325\tval-merror:0.052500\n",
      "[227]\ttrain-merror:0.018325\tval-merror:0.053000\n",
      "[228]\ttrain-merror:0.018300\tval-merror:0.053000\n",
      "[229]\ttrain-merror:0.018275\tval-merror:0.053000\n",
      "[230]\ttrain-merror:0.018250\tval-merror:0.052500\n",
      "[231]\ttrain-merror:0.018150\tval-merror:0.052500\n",
      "[232]\ttrain-merror:0.018100\tval-merror:0.052500\n",
      "[233]\ttrain-merror:0.018150\tval-merror:0.052500\n",
      "[234]\ttrain-merror:0.018075\tval-merror:0.053000\n",
      "[235]\ttrain-merror:0.018150\tval-merror:0.053000\n",
      "[236]\ttrain-merror:0.018050\tval-merror:0.053000\n",
      "[237]\ttrain-merror:0.018025\tval-merror:0.052500\n",
      "[238]\ttrain-merror:0.018000\tval-merror:0.052500\n",
      "[239]\ttrain-merror:0.017950\tval-merror:0.052500\n",
      "[240]\ttrain-merror:0.017975\tval-merror:0.053000\n",
      "[241]\ttrain-merror:0.017950\tval-merror:0.053000\n",
      "[242]\ttrain-merror:0.017850\tval-merror:0.053000\n",
      "[243]\ttrain-merror:0.017925\tval-merror:0.053000\n",
      "[244]\ttrain-merror:0.017850\tval-merror:0.053000\n",
      "[245]\ttrain-merror:0.017800\tval-merror:0.052500\n",
      "[246]\ttrain-merror:0.017775\tval-merror:0.053500\n",
      "[247]\ttrain-merror:0.017800\tval-merror:0.053500\n",
      "[248]\ttrain-merror:0.017800\tval-merror:0.053500\n",
      "[249]\ttrain-merror:0.017750\tval-merror:0.053500\n",
      "[250]\ttrain-merror:0.017725\tval-merror:0.053500\n",
      "[251]\ttrain-merror:0.017650\tval-merror:0.053500\n",
      "[252]\ttrain-merror:0.017575\tval-merror:0.053500\n",
      "[253]\ttrain-merror:0.017575\tval-merror:0.053000\n",
      "[254]\ttrain-merror:0.017575\tval-merror:0.053500\n",
      "[255]\ttrain-merror:0.017550\tval-merror:0.052500\n",
      "[256]\ttrain-merror:0.017575\tval-merror:0.052500\n",
      "[257]\ttrain-merror:0.017575\tval-merror:0.052000\n",
      "[258]\ttrain-merror:0.017500\tval-merror:0.052000\n",
      "[259]\ttrain-merror:0.017450\tval-merror:0.053000\n",
      "[260]\ttrain-merror:0.017400\tval-merror:0.052000\n",
      "[261]\ttrain-merror:0.017350\tval-merror:0.052000\n",
      "[262]\ttrain-merror:0.017350\tval-merror:0.052500\n",
      "[263]\ttrain-merror:0.017250\tval-merror:0.052000\n",
      "[264]\ttrain-merror:0.017275\tval-merror:0.052500\n",
      "[265]\ttrain-merror:0.017300\tval-merror:0.052500\n",
      "[266]\ttrain-merror:0.017250\tval-merror:0.052500\n",
      "[267]\ttrain-merror:0.017225\tval-merror:0.052500\n",
      "[268]\ttrain-merror:0.017200\tval-merror:0.052500\n",
      "[269]\ttrain-merror:0.017150\tval-merror:0.052500\n",
      "[270]\ttrain-merror:0.017150\tval-merror:0.052500\n",
      "[271]\ttrain-merror:0.017075\tval-merror:0.052500\n",
      "[272]\ttrain-merror:0.017000\tval-merror:0.052500\n",
      "[273]\ttrain-merror:0.016950\tval-merror:0.052500\n",
      "[274]\ttrain-merror:0.016950\tval-merror:0.052500\n",
      "[275]\ttrain-merror:0.016900\tval-merror:0.052500\n",
      "[276]\ttrain-merror:0.016850\tval-merror:0.052500\n",
      "[277]\ttrain-merror:0.016800\tval-merror:0.052000\n",
      "[278]\ttrain-merror:0.016800\tval-merror:0.052500\n",
      "[279]\ttrain-merror:0.016775\tval-merror:0.052500\n",
      "[280]\ttrain-merror:0.016700\tval-merror:0.052000\n",
      "[281]\ttrain-merror:0.016725\tval-merror:0.052000\n",
      "[282]\ttrain-merror:0.016725\tval-merror:0.052000\n",
      "[283]\ttrain-merror:0.016675\tval-merror:0.052000\n",
      "[284]\ttrain-merror:0.016600\tval-merror:0.052500\n",
      "[285]\ttrain-merror:0.016575\tval-merror:0.052000\n",
      "[286]\ttrain-merror:0.016500\tval-merror:0.051500\n",
      "[287]\ttrain-merror:0.016500\tval-merror:0.051000\n",
      "[288]\ttrain-merror:0.016475\tval-merror:0.051500\n",
      "[289]\ttrain-merror:0.016500\tval-merror:0.051500\n",
      "[290]\ttrain-merror:0.016500\tval-merror:0.051500\n",
      "[291]\ttrain-merror:0.016475\tval-merror:0.051000\n",
      "[292]\ttrain-merror:0.016425\tval-merror:0.051000\n",
      "[293]\ttrain-merror:0.016400\tval-merror:0.051000\n",
      "[294]\ttrain-merror:0.016400\tval-merror:0.050500\n",
      "[295]\ttrain-merror:0.016325\tval-merror:0.050500\n",
      "[296]\ttrain-merror:0.016300\tval-merror:0.050500\n",
      "[297]\ttrain-merror:0.016300\tval-merror:0.051000\n",
      "[298]\ttrain-merror:0.016300\tval-merror:0.051000\n",
      "[299]\ttrain-merror:0.016275\tval-merror:0.051000\n",
      "[300]\ttrain-merror:0.016225\tval-merror:0.051000\n",
      "[301]\ttrain-merror:0.016200\tval-merror:0.051000\n",
      "[302]\ttrain-merror:0.016175\tval-merror:0.051000\n",
      "[303]\ttrain-merror:0.016200\tval-merror:0.051000\n",
      "[304]\ttrain-merror:0.016150\tval-merror:0.051000\n",
      "[305]\ttrain-merror:0.016175\tval-merror:0.050500\n",
      "[306]\ttrain-merror:0.016100\tval-merror:0.051000\n",
      "[307]\ttrain-merror:0.016100\tval-merror:0.051000\n",
      "[308]\ttrain-merror:0.016075\tval-merror:0.051000\n",
      "[309]\ttrain-merror:0.016075\tval-merror:0.051000\n",
      "[310]\ttrain-merror:0.016075\tval-merror:0.050500\n",
      "[311]\ttrain-merror:0.016100\tval-merror:0.050500\n",
      "[312]\ttrain-merror:0.016025\tval-merror:0.050500\n",
      "[313]\ttrain-merror:0.016050\tval-merror:0.050500\n",
      "[314]\ttrain-merror:0.016000\tval-merror:0.050500\n",
      "[315]\ttrain-merror:0.015975\tval-merror:0.050500\n",
      "[316]\ttrain-merror:0.016000\tval-merror:0.050500\n",
      "[317]\ttrain-merror:0.016000\tval-merror:0.050500\n",
      "[318]\ttrain-merror:0.015975\tval-merror:0.050500\n",
      "[319]\ttrain-merror:0.015950\tval-merror:0.050500\n",
      "[320]\ttrain-merror:0.015975\tval-merror:0.050500\n",
      "[321]\ttrain-merror:0.015925\tval-merror:0.050500\n",
      "[322]\ttrain-merror:0.015900\tval-merror:0.050500\n",
      "[323]\ttrain-merror:0.015875\tval-merror:0.050500\n",
      "[324]\ttrain-merror:0.015850\tval-merror:0.050500\n",
      "[325]\ttrain-merror:0.015850\tval-merror:0.050500\n",
      "[326]\ttrain-merror:0.015825\tval-merror:0.050500\n",
      "[327]\ttrain-merror:0.015800\tval-merror:0.050500\n",
      "[328]\ttrain-merror:0.015825\tval-merror:0.050500\n",
      "[329]\ttrain-merror:0.015825\tval-merror:0.050500\n",
      "[330]\ttrain-merror:0.015875\tval-merror:0.050500\n",
      "[331]\ttrain-merror:0.015850\tval-merror:0.050500\n",
      "[332]\ttrain-merror:0.015850\tval-merror:0.050500\n",
      "[333]\ttrain-merror:0.015825\tval-merror:0.050500\n",
      "[334]\ttrain-merror:0.015825\tval-merror:0.050500\n",
      "[335]\ttrain-merror:0.015775\tval-merror:0.050500\n",
      "[336]\ttrain-merror:0.015775\tval-merror:0.050500\n",
      "[337]\ttrain-merror:0.015750\tval-merror:0.050500\n",
      "[338]\ttrain-merror:0.015675\tval-merror:0.050500\n",
      "[339]\ttrain-merror:0.015675\tval-merror:0.050500\n",
      "[340]\ttrain-merror:0.015625\tval-merror:0.050500\n",
      "[341]\ttrain-merror:0.015550\tval-merror:0.050500\n",
      "[342]\ttrain-merror:0.015550\tval-merror:0.050500\n",
      "[343]\ttrain-merror:0.015550\tval-merror:0.050500\n",
      "[344]\ttrain-merror:0.015450\tval-merror:0.050500\n",
      "[345]\ttrain-merror:0.015450\tval-merror:0.050500\n",
      "[346]\ttrain-merror:0.015400\tval-merror:0.050500\n",
      "[347]\ttrain-merror:0.015375\tval-merror:0.050500\n",
      "[348]\ttrain-merror:0.015250\tval-merror:0.050500\n",
      "[349]\ttrain-merror:0.015275\tval-merror:0.050500\n",
      "[350]\ttrain-merror:0.015300\tval-merror:0.050500\n",
      "[351]\ttrain-merror:0.015275\tval-merror:0.050500\n",
      "[352]\ttrain-merror:0.015175\tval-merror:0.050500\n",
      "[353]\ttrain-merror:0.015100\tval-merror:0.051000\n",
      "[354]\ttrain-merror:0.015075\tval-merror:0.051000\n",
      "[355]\ttrain-merror:0.015025\tval-merror:0.051000\n",
      "[356]\ttrain-merror:0.014975\tval-merror:0.051000\n",
      "[357]\ttrain-merror:0.014950\tval-merror:0.051000\n",
      "[358]\ttrain-merror:0.014875\tval-merror:0.050500\n",
      "[359]\ttrain-merror:0.014825\tval-merror:0.050500\n",
      "[360]\ttrain-merror:0.014850\tval-merror:0.051000\n",
      "[361]\ttrain-merror:0.014800\tval-merror:0.051000\n",
      "[362]\ttrain-merror:0.014775\tval-merror:0.050500\n",
      "[363]\ttrain-merror:0.014775\tval-merror:0.050500\n",
      "[364]\ttrain-merror:0.014725\tval-merror:0.050500\n",
      "[365]\ttrain-merror:0.014750\tval-merror:0.050500\n",
      "[366]\ttrain-merror:0.014675\tval-merror:0.050500\n",
      "[367]\ttrain-merror:0.014650\tval-merror:0.050500\n",
      "[368]\ttrain-merror:0.014625\tval-merror:0.050500\n",
      "[369]\ttrain-merror:0.014525\tval-merror:0.050500\n",
      "[370]\ttrain-merror:0.014450\tval-merror:0.050000\n",
      "[371]\ttrain-merror:0.014525\tval-merror:0.050000\n",
      "[372]\ttrain-merror:0.014475\tval-merror:0.050000\n",
      "[373]\ttrain-merror:0.014525\tval-merror:0.050000\n",
      "[374]\ttrain-merror:0.014475\tval-merror:0.050000\n",
      "[375]\ttrain-merror:0.014475\tval-merror:0.050000\n",
      "[376]\ttrain-merror:0.014500\tval-merror:0.050000\n",
      "[377]\ttrain-merror:0.014500\tval-merror:0.050000\n",
      "[378]\ttrain-merror:0.014500\tval-merror:0.050500\n",
      "[379]\ttrain-merror:0.014450\tval-merror:0.050500\n",
      "[380]\ttrain-merror:0.014425\tval-merror:0.050500\n",
      "[381]\ttrain-merror:0.014350\tval-merror:0.050500\n",
      "[382]\ttrain-merror:0.014350\tval-merror:0.050500\n",
      "[383]\ttrain-merror:0.014350\tval-merror:0.050500\n",
      "[384]\ttrain-merror:0.014350\tval-merror:0.050500\n",
      "[385]\ttrain-merror:0.014325\tval-merror:0.050500\n",
      "[386]\ttrain-merror:0.014300\tval-merror:0.050500\n",
      "[387]\ttrain-merror:0.014275\tval-merror:0.050500\n",
      "[388]\ttrain-merror:0.014275\tval-merror:0.050500\n",
      "[389]\ttrain-merror:0.014175\tval-merror:0.050500\n",
      "[390]\ttrain-merror:0.014200\tval-merror:0.050500\n",
      "[391]\ttrain-merror:0.014125\tval-merror:0.050500\n",
      "[392]\ttrain-merror:0.014100\tval-merror:0.050500\n",
      "[393]\ttrain-merror:0.014050\tval-merror:0.050500\n",
      "[394]\ttrain-merror:0.013975\tval-merror:0.050500\n",
      "[395]\ttrain-merror:0.013950\tval-merror:0.050500\n",
      "[396]\ttrain-merror:0.013900\tval-merror:0.050500\n",
      "[397]\ttrain-merror:0.013900\tval-merror:0.050500\n",
      "[398]\ttrain-merror:0.013825\tval-merror:0.050500\n",
      "[399]\ttrain-merror:0.013825\tval-merror:0.050500\n",
      "[400]\ttrain-merror:0.013800\tval-merror:0.050500\n",
      "[401]\ttrain-merror:0.013775\tval-merror:0.050500\n",
      "[402]\ttrain-merror:0.013750\tval-merror:0.050500\n",
      "[403]\ttrain-merror:0.013775\tval-merror:0.050500\n",
      "[404]\ttrain-merror:0.013775\tval-merror:0.050500\n",
      "[405]\ttrain-merror:0.013775\tval-merror:0.050500\n",
      "[406]\ttrain-merror:0.013650\tval-merror:0.050500\n",
      "[407]\ttrain-merror:0.013625\tval-merror:0.050000\n",
      "[408]\ttrain-merror:0.013575\tval-merror:0.050000\n",
      "[409]\ttrain-merror:0.013525\tval-merror:0.049500\n",
      "[410]\ttrain-merror:0.013550\tval-merror:0.049500\n",
      "[411]\ttrain-merror:0.013500\tval-merror:0.049500\n",
      "[412]\ttrain-merror:0.013350\tval-merror:0.049500\n",
      "[413]\ttrain-merror:0.013350\tval-merror:0.049500\n",
      "[414]\ttrain-merror:0.013300\tval-merror:0.049500\n",
      "[415]\ttrain-merror:0.013325\tval-merror:0.049500\n",
      "[416]\ttrain-merror:0.013300\tval-merror:0.049500\n",
      "[417]\ttrain-merror:0.013325\tval-merror:0.049500\n",
      "[418]\ttrain-merror:0.013275\tval-merror:0.049500\n",
      "[419]\ttrain-merror:0.013300\tval-merror:0.049500\n",
      "[420]\ttrain-merror:0.013200\tval-merror:0.049500\n",
      "[421]\ttrain-merror:0.013200\tval-merror:0.049500\n",
      "[422]\ttrain-merror:0.013100\tval-merror:0.049500\n",
      "[423]\ttrain-merror:0.013150\tval-merror:0.049500\n",
      "[424]\ttrain-merror:0.013125\tval-merror:0.049500\n",
      "[425]\ttrain-merror:0.013125\tval-merror:0.049500\n",
      "[426]\ttrain-merror:0.013075\tval-merror:0.049500\n",
      "[427]\ttrain-merror:0.013050\tval-merror:0.049500\n",
      "[428]\ttrain-merror:0.013075\tval-merror:0.049500\n",
      "[429]\ttrain-merror:0.012975\tval-merror:0.049500\n",
      "[430]\ttrain-merror:0.012950\tval-merror:0.049500\n",
      "[431]\ttrain-merror:0.012950\tval-merror:0.049500\n",
      "[432]\ttrain-merror:0.012875\tval-merror:0.049500\n",
      "[433]\ttrain-merror:0.012850\tval-merror:0.049500\n",
      "[434]\ttrain-merror:0.012900\tval-merror:0.049500\n",
      "[435]\ttrain-merror:0.012850\tval-merror:0.049500\n",
      "[436]\ttrain-merror:0.012775\tval-merror:0.049500\n",
      "[437]\ttrain-merror:0.012700\tval-merror:0.049500\n",
      "[438]\ttrain-merror:0.012650\tval-merror:0.049500\n",
      "[439]\ttrain-merror:0.012625\tval-merror:0.049500\n",
      "[440]\ttrain-merror:0.012625\tval-merror:0.049500\n",
      "[441]\ttrain-merror:0.012600\tval-merror:0.049500\n",
      "[442]\ttrain-merror:0.012600\tval-merror:0.049500\n",
      "[443]\ttrain-merror:0.012525\tval-merror:0.050000\n",
      "[444]\ttrain-merror:0.012500\tval-merror:0.050000\n",
      "[445]\ttrain-merror:0.012450\tval-merror:0.050000\n",
      "[446]\ttrain-merror:0.012400\tval-merror:0.050000\n",
      "[447]\ttrain-merror:0.012425\tval-merror:0.050000\n",
      "[448]\ttrain-merror:0.012400\tval-merror:0.050000\n",
      "[449]\ttrain-merror:0.012400\tval-merror:0.050000\n",
      "[450]\ttrain-merror:0.012375\tval-merror:0.050000\n",
      "[451]\ttrain-merror:0.012325\tval-merror:0.050000\n",
      "[452]\ttrain-merror:0.012275\tval-merror:0.050500\n",
      "[453]\ttrain-merror:0.012225\tval-merror:0.050500\n",
      "[454]\ttrain-merror:0.012125\tval-merror:0.050000\n",
      "[455]\ttrain-merror:0.012125\tval-merror:0.050000\n",
      "[456]\ttrain-merror:0.012125\tval-merror:0.050500\n",
      "[457]\ttrain-merror:0.012075\tval-merror:0.050500\n",
      "[458]\ttrain-merror:0.012025\tval-merror:0.050500\n",
      "[459]\ttrain-merror:0.012025\tval-merror:0.050500\n",
      "[460]\ttrain-merror:0.011975\tval-merror:0.050000\n",
      "[461]\ttrain-merror:0.012000\tval-merror:0.050000\n",
      "[462]\ttrain-merror:0.012000\tval-merror:0.050000\n",
      "[463]\ttrain-merror:0.012025\tval-merror:0.050000\n",
      "[464]\ttrain-merror:0.012025\tval-merror:0.050000\n",
      "[465]\ttrain-merror:0.011950\tval-merror:0.050000\n",
      "[466]\ttrain-merror:0.011975\tval-merror:0.050000\n",
      "[467]\ttrain-merror:0.011925\tval-merror:0.050000\n",
      "[468]\ttrain-merror:0.011900\tval-merror:0.050000\n",
      "[469]\ttrain-merror:0.011825\tval-merror:0.050000\n",
      "[470]\ttrain-merror:0.011800\tval-merror:0.050000\n",
      "[471]\ttrain-merror:0.011750\tval-merror:0.050000\n",
      "[472]\ttrain-merror:0.011725\tval-merror:0.050000\n",
      "[473]\ttrain-merror:0.011725\tval-merror:0.050000\n",
      "[474]\ttrain-merror:0.011700\tval-merror:0.050000\n",
      "[475]\ttrain-merror:0.011700\tval-merror:0.050000\n",
      "[476]\ttrain-merror:0.011650\tval-merror:0.050000\n",
      "[477]\ttrain-merror:0.011625\tval-merror:0.050000\n",
      "[478]\ttrain-merror:0.011625\tval-merror:0.050000\n",
      "[479]\ttrain-merror:0.011600\tval-merror:0.050000\n",
      "[480]\ttrain-merror:0.011600\tval-merror:0.050000\n",
      "[481]\ttrain-merror:0.011575\tval-merror:0.049500\n",
      "[482]\ttrain-merror:0.011575\tval-merror:0.049500\n",
      "[483]\ttrain-merror:0.011500\tval-merror:0.049000\n",
      "[484]\ttrain-merror:0.011550\tval-merror:0.049000\n",
      "[485]\ttrain-merror:0.011550\tval-merror:0.049000\n",
      "[486]\ttrain-merror:0.011475\tval-merror:0.049000\n",
      "[487]\ttrain-merror:0.011450\tval-merror:0.049500\n",
      "[488]\ttrain-merror:0.011400\tval-merror:0.049000\n",
      "[489]\ttrain-merror:0.011425\tval-merror:0.049000\n",
      "[490]\ttrain-merror:0.011375\tval-merror:0.049000\n",
      "[491]\ttrain-merror:0.011375\tval-merror:0.049500\n",
      "[492]\ttrain-merror:0.011325\tval-merror:0.049500\n",
      "[493]\ttrain-merror:0.011350\tval-merror:0.049500\n",
      "[494]\ttrain-merror:0.011350\tval-merror:0.049500\n",
      "[495]\ttrain-merror:0.011375\tval-merror:0.049500\n",
      "[496]\ttrain-merror:0.011325\tval-merror:0.049500\n",
      "[497]\ttrain-merror:0.011300\tval-merror:0.049500\n",
      "[498]\ttrain-merror:0.011250\tval-merror:0.049500\n",
      "[499]\ttrain-merror:0.011200\tval-merror:0.049500\n",
      "[500]\ttrain-merror:0.011175\tval-merror:0.049500\n",
      "[501]\ttrain-merror:0.011150\tval-merror:0.049500\n",
      "[502]\ttrain-merror:0.011150\tval-merror:0.049500\n",
      "[503]\ttrain-merror:0.011100\tval-merror:0.049000\n",
      "[504]\ttrain-merror:0.011075\tval-merror:0.049000\n",
      "[505]\ttrain-merror:0.011100\tval-merror:0.049000\n",
      "[506]\ttrain-merror:0.011075\tval-merror:0.049000\n",
      "[507]\ttrain-merror:0.011075\tval-merror:0.049000\n",
      "[508]\ttrain-merror:0.011075\tval-merror:0.049000\n",
      "[509]\ttrain-merror:0.011075\tval-merror:0.049000\n",
      "[510]\ttrain-merror:0.011050\tval-merror:0.049000\n",
      "[511]\ttrain-merror:0.011075\tval-merror:0.048500\n",
      "[512]\ttrain-merror:0.011075\tval-merror:0.048500\n",
      "[513]\ttrain-merror:0.011075\tval-merror:0.048500\n",
      "[514]\ttrain-merror:0.011050\tval-merror:0.048500\n",
      "[515]\ttrain-merror:0.011025\tval-merror:0.048500\n",
      "[516]\ttrain-merror:0.011025\tval-merror:0.048500\n",
      "[517]\ttrain-merror:0.011025\tval-merror:0.048500\n",
      "[518]\ttrain-merror:0.011025\tval-merror:0.049000\n",
      "[519]\ttrain-merror:0.011025\tval-merror:0.049000\n",
      "[520]\ttrain-merror:0.011025\tval-merror:0.049000\n",
      "[521]\ttrain-merror:0.011025\tval-merror:0.048500\n",
      "[522]\ttrain-merror:0.011025\tval-merror:0.049000\n",
      "[523]\ttrain-merror:0.011000\tval-merror:0.049000\n",
      "[524]\ttrain-merror:0.011000\tval-merror:0.049000\n",
      "[525]\ttrain-merror:0.011000\tval-merror:0.049000\n",
      "[526]\ttrain-merror:0.010975\tval-merror:0.049000\n",
      "[527]\ttrain-merror:0.010950\tval-merror:0.049000\n",
      "[528]\ttrain-merror:0.010950\tval-merror:0.049000\n",
      "[529]\ttrain-merror:0.010900\tval-merror:0.049000\n",
      "[530]\ttrain-merror:0.010850\tval-merror:0.049000\n",
      "[531]\ttrain-merror:0.010850\tval-merror:0.049000\n",
      "[532]\ttrain-merror:0.010850\tval-merror:0.049000\n",
      "[533]\ttrain-merror:0.010800\tval-merror:0.049000\n",
      "[534]\ttrain-merror:0.010775\tval-merror:0.049000\n",
      "[535]\ttrain-merror:0.010750\tval-merror:0.049000\n",
      "[536]\ttrain-merror:0.010775\tval-merror:0.049000\n",
      "[537]\ttrain-merror:0.010775\tval-merror:0.049000\n",
      "[538]\ttrain-merror:0.010725\tval-merror:0.049000\n",
      "[539]\ttrain-merror:0.010700\tval-merror:0.049000\n",
      "[540]\ttrain-merror:0.010625\tval-merror:0.049000\n",
      "[541]\ttrain-merror:0.010625\tval-merror:0.049500\n",
      "[542]\ttrain-merror:0.010625\tval-merror:0.049500\n",
      "[543]\ttrain-merror:0.010575\tval-merror:0.049500\n",
      "[544]\ttrain-merror:0.010550\tval-merror:0.049500\n",
      "[545]\ttrain-merror:0.010525\tval-merror:0.049500\n",
      "[546]\ttrain-merror:0.010500\tval-merror:0.049500\n",
      "[547]\ttrain-merror:0.010475\tval-merror:0.049000\n",
      "[548]\ttrain-merror:0.010450\tval-merror:0.049000\n",
      "[549]\ttrain-merror:0.010350\tval-merror:0.049000\n",
      "[550]\ttrain-merror:0.010275\tval-merror:0.049000\n",
      "[551]\ttrain-merror:0.010325\tval-merror:0.049000\n",
      "[552]\ttrain-merror:0.010350\tval-merror:0.049000\n",
      "[553]\ttrain-merror:0.010325\tval-merror:0.049000\n",
      "[554]\ttrain-merror:0.010275\tval-merror:0.049000\n",
      "[555]\ttrain-merror:0.010300\tval-merror:0.048500\n",
      "[556]\ttrain-merror:0.010325\tval-merror:0.048500\n",
      "[557]\ttrain-merror:0.010225\tval-merror:0.048500\n",
      "[558]\ttrain-merror:0.010200\tval-merror:0.048500\n",
      "[559]\ttrain-merror:0.010100\tval-merror:0.048500\n",
      "[560]\ttrain-merror:0.010125\tval-merror:0.048500\n",
      "[561]\ttrain-merror:0.010075\tval-merror:0.048500\n",
      "[562]\ttrain-merror:0.010100\tval-merror:0.048500\n",
      "[563]\ttrain-merror:0.010025\tval-merror:0.048500\n",
      "[564]\ttrain-merror:0.010050\tval-merror:0.048500\n",
      "[565]\ttrain-merror:0.010000\tval-merror:0.048500\n",
      "[566]\ttrain-merror:0.009925\tval-merror:0.048500\n",
      "[567]\ttrain-merror:0.009950\tval-merror:0.048500\n",
      "[568]\ttrain-merror:0.009900\tval-merror:0.049000\n",
      "[569]\ttrain-merror:0.009900\tval-merror:0.049000\n",
      "[570]\ttrain-merror:0.009875\tval-merror:0.049000\n",
      "[571]\ttrain-merror:0.009850\tval-merror:0.049000\n",
      "[572]\ttrain-merror:0.009900\tval-merror:0.049000\n",
      "[573]\ttrain-merror:0.009875\tval-merror:0.049000\n",
      "[574]\ttrain-merror:0.009850\tval-merror:0.049000\n",
      "[575]\ttrain-merror:0.009825\tval-merror:0.049000\n",
      "[576]\ttrain-merror:0.009825\tval-merror:0.049000\n",
      "[577]\ttrain-merror:0.009825\tval-merror:0.049000\n",
      "[578]\ttrain-merror:0.009800\tval-merror:0.049000\n",
      "[579]\ttrain-merror:0.009725\tval-merror:0.049000\n",
      "[580]\ttrain-merror:0.009725\tval-merror:0.049000\n",
      "[581]\ttrain-merror:0.009750\tval-merror:0.049000\n",
      "[582]\ttrain-merror:0.009700\tval-merror:0.049000\n",
      "[583]\ttrain-merror:0.009700\tval-merror:0.049000\n",
      "[584]\ttrain-merror:0.009650\tval-merror:0.049000\n",
      "[585]\ttrain-merror:0.009650\tval-merror:0.049000\n",
      "[586]\ttrain-merror:0.009525\tval-merror:0.049000\n",
      "[587]\ttrain-merror:0.009525\tval-merror:0.049000\n",
      "[588]\ttrain-merror:0.009475\tval-merror:0.049000\n",
      "[589]\ttrain-merror:0.009500\tval-merror:0.049000\n",
      "[590]\ttrain-merror:0.009550\tval-merror:0.048500\n",
      "[591]\ttrain-merror:0.009550\tval-merror:0.048500\n",
      "[592]\ttrain-merror:0.009525\tval-merror:0.048500\n",
      "[593]\ttrain-merror:0.009525\tval-merror:0.048500\n",
      "[594]\ttrain-merror:0.009475\tval-merror:0.048500\n",
      "[595]\ttrain-merror:0.009450\tval-merror:0.048500\n",
      "[596]\ttrain-merror:0.009400\tval-merror:0.048500\n",
      "[597]\ttrain-merror:0.009375\tval-merror:0.048500\n",
      "[598]\ttrain-merror:0.009400\tval-merror:0.048500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 54min 54s, sys: 1.22 s, total: 1h 54min 55s\n",
      "Wall time: 19min 11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[599]\ttrain-merror:0.009400\tval-merror:0.048500\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# model\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import time \n",
    "\n",
    "params={\n",
    "'booster':'gbtree',\n",
    "# 这里手写数字是0-9，是一个多类的问题，因此采用了multisoft多分类器，\n",
    "'objective': 'multi:softmax', \n",
    "'num_class':10, # 类数，与 multisoftmax 并用\n",
    "'gamma':0.05,  # 在树的叶子节点下一个分区的最小损失，越大算法模型越保守 。[0:]\n",
    "'max_depth':12, # 构建树的深度 [1:]\n",
    "#'lambda':450,  # L2 正则项权重\n",
    "'subsample':0.4, # 采样训练数据，设置为0.5，随机选择一般的数据实例 (0:1]\n",
    "'colsample_bytree':0.7, # 构建树树时的采样比率 (0:1]\n",
    "#'min_child_weight':12, # 节点的最少特征数\n",
    "'silent':1 ,\n",
    "'eta': 0.005, # 学习率\n",
    "'seed':710,\n",
    "'nthread':6,# cpu 线程数\n",
    "}\n",
    "\n",
    "plst = list(params.items())\n",
    "num_rounds = 600 # 迭代次数, 最好选500\n",
    "\n",
    "xgtest = xgb.DMatrix(test)\n",
    "\n",
    "xgtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "xgval = xgb.DMatrix(x_valid, label=y_valid)\n",
    "watchlist = [(xgtrain, 'train'),(xgval, 'val')]\n",
    "\n",
    "history = model = xgb.train(plst, xgtrain, num_rounds, watchlist)# , early_stopping_rounds=100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_model('xgb.model') # 用于存储训练出的模型\n",
    "\n",
    "preds = model.predict(xgtest,ntree_limit=model.best_iteration)\n",
    "\n",
    "# 将预测结果写入文件\n",
    "np.savetxt('submission_xgb_MultiSoftmax.csv',np.c_[range(1,len(test)+1),preds],\n",
    "                delimiter=',',header='ImageId,Label',comments='',fmt='%d')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kaggle result:  0.95414"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
