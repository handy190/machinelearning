{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate JayChou Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'想要有直升机\\n想要和你飞到宇宙去\\n想要和你融化在一起\\n融化在宇宙里\\n我每天每天每'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('jaychou_lyrics.txt' ,'r', encoding='utf-8') as fr:\n",
    "    corpus_chars = fr.read()\n",
    "corpus_chars[:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_chars = corpus_chars.replace('\\n', ' ').replace('\\r', ' ')\n",
    "corpus_chars = corpus_chars[:10000]#只取前10000个词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1027"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_char = list(set(corpus_chars))\n",
    "char_to_idx = dict([(char, i) for i, char in enumerate(idx_to_char)])\n",
    "vocab_size = len(char_to_idx)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9900, 100) (9900,)\n",
      "(9900, 100) (9900, 1027)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "\n",
    "seq_length = 100  # 句子长度, 根据100个词，预测第101个词\n",
    "n_words = len(corpus_chars)\n",
    "x_data = []\n",
    "y_data = []\n",
    "for i in range(0, n_words - seq_length, 1):\n",
    "    seq_in = corpus_chars[i:i + seq_length]\n",
    "    seq_out = corpus_chars[i + seq_length]\n",
    "    x_data.append([char_to_idx[char] for char in seq_in])\n",
    "    y_data.append(char_to_idx[seq_out])\n",
    "    \n",
    "x_data = np.array(x_data)    \n",
    "y_data = np.array(y_data)\n",
    "print(x_data.shape, y_data.shape)\n",
    "y_data = np_utils.to_categorical(y_data)\n",
    "print(x_data.shape, y_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. build and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model.py at background is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "6300/9900 [==================>...........] - ETA: 11:30 - loss: 5.9839"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM, Embedding\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 512, input_length=seq_length))\n",
    "model.add(LSTM(512, input_shape=(seq_length, 512), return_sequences=True))\n",
    "model.add(LSTM(1024))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "# train\n",
    "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam)\n",
    "\n",
    "# 存储每一次迭代的网络权重\n",
    "filepath = \"weights-improvement={epoch:02d}-{loss:4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "model.fit(x_data, y_data, epochs=30, batch_size=100, callbacks=callbacks_list, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generated models\n",
    "\n",
    "```\n",
    "-rw-r--r--  1 root root 115M Jan 25 16:45 weights-improvement=01-5.935630.hdf5\n",
    "-rw-r--r--  1 root root 115M Jan 25 17:08 weights-improvement=02-5.581992.hdf5\n",
    "-rw-r--r--  1 root root 115M Jan 25 17:32 weights-improvement=03-5.272040.hdf5\n",
    "-rw-r--r--  1 root root 115M Jan 25 17:56 weights-improvement=04-4.658247.hdf5\n",
    "-rw-r--r--  1 root root 115M Jan 25 18:20 weights-improvement=05-3.769422.hdf5\n",
    "-rw-r--r--  1 root root 115M Jan 25 18:44 weights-improvement=06-2.664625.hdf5\n",
    "-rw-r--r--  1 root root 115M Jan 25 19:07 weights-improvement=07-1.619380.hdf5\n",
    "-rw-r--r--  1 root root 115M Jan 25 19:31 weights-improvement=08-0.884530.hdf5\n",
    "-rw-r--r--  1 root root 115M Jan 25 19:55 weights-improvement=09-0.461911.hdf5\n",
    "-rw-r--r--  1 root root 115M Jan 25 20:19 weights-improvement=10-0.249079.hdf5\n",
    "-rw-r--r--  1 root root 115M Jan 25 20:43 weights-improvement=11-0.139019.hdf5\n",
    "-rw-r--r--  1 root root 115M Jan 25 21:06 weights-improvement=12-0.093872.hdf5\n",
    "-rw-r--r--  1 root root 115M Jan 25 21:30 weights-improvement=13-0.068452.hdf5\n",
    "-rw-r--r--  1 root root 115M Jan 25 21:54 weights-improvement=14-0.055126.hdf5\n",
    "-rw-r--r--  1 root root 115M Jan 25 22:18 weights-improvement=15-0.046440.hdf5\n",
    "-rw-r--r--  1 root root 115M Jan 25 22:42 weights-improvement=16-0.040797.hdf5\n",
    "-rw-r--r--  1 root root 115M Jan 25 23:05 weights-improvement=17-0.037703.hdf5\n",
    "-rw-r--r--  1 root root 115M Jan 25 23:29 weights-improvement=18-0.036534.hdf5\n",
    "-rw-r--r--  1 root root 115M Jan 25 23:53 weights-improvement=19-0.032406.hdf5\n",
    "-rw-r--r--  1 root root 115M Jan 26 00:17 weights-improvement=20-0.030007.hdf5\n",
    "-rw-r--r--  1 root root 115M Jan 26 01:05 weights-improvement=22-0.027981.hdf5\n",
    "-rw-r--r--  1 root root 115M Jan 26 02:16 weights-improvement=25-0.023679.hdf5\n",
    "-rw-r--r--  1 root root 115M Jan 26 06:38 weights-improvement=36-0.022905.hdf5\n",
    "-rw-r--r--  1 root root 115M Jan 26 07:02 weights-improvement=37-0.017469.hdf5\n",
    "-rw-r--r--  1 root root 115M Jan 26 07:26 weights-improvement=38-0.016000.hdf5\n",
    "-rw-r--r--  1 root root 115M Jan 26 07:49 weights-improvement=39-0.014843.hdf5\n",
    "-rw-r--r--  1 root root 115M Jan 26 08:37 weights-improvement=41-0.014568.hdf5\n",
    "-rw-r--r--  1 root root 115M Jan 26 09:01 weights-improvement=42-0.013628.hdf5\n",
    "-rw-r--r--  1 root root 115M Jan 26 09:25 weights-improvement=43-0.012938.hdf5\n",
    "-rw-r--r--  1 root root 115M Jan 26 10:12 weights-improvement=45-0.011493.hdf5\n",
    "-rw-r--r--  1 root root 115M Jan 26 11:24 weights-improvement=48-0.010859.hdf5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/envtf/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n",
      "/root/anaconda3/envs/envtf/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/root/anaconda3/envs/envtf/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model2 = load_model('weights-improvement=48-0.010859.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 512)          525824    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 512)          2099200   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 1024)              6295552   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1027)              1052675   \n",
      "=================================================================\n",
      "Total params: 9,973,251\n",
      "Trainable params: 9,973,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. generate jaychou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# 原理：根据100个词，预测第101个词\n",
    "# 原始的100个词如下\n",
    "\n",
    "\n",
    "str100 = '''今天的你，明天的我，大家的彩虹，一起乘着飞机，今天的你，明天的我，大家的彩虹，今天的你，明天的我，大家的彩虹，今天的你，明天的我，大家的彩虹，今天的你，明天的我，大家的彩虹，今天的你，明天的我，大家的彩虹\n",
    "'''\n",
    "print( len(str100) )\n",
    "\n",
    "str100 = str100.replace('\\n', ' ').replace('\\r', ' ').replace('，', ' ')\n",
    "str100 = str100[:100]#只取前100个词\n",
    "print( len(str100) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = np.array([[char_to_idx[char] for char in str100]])# 前100个字符\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([680])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.predict_classes( x_test )# 预测帝101个字符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'盘'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_char[680]# 第101个字符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['盘', '着', '才', '形', '枪', '绪', '有', '鸠', '喜', '实', '盘', '扫', '下', '大', '欢', '拽', '宁', '昏', '果', '彿', '透', '起', '盘', '单', '瑰', '爽', '形', '枪', '有', '妈', '联', '盘', '正', '大', '产', '该', '植', '鳅', '荒', '敌', '有', '必', '坏', '狂', '狂', '袋', '温', '走', '银', '盘', '难', '这', '有', '盘', '藤', '些', '消', '盘', '产', '都', '思', '螂', '盘', '着', '底', '为', '盘', '有', '疼', '迎', '盘', '些', '决', '殿', '送', '忙', '盘', '龙', '再', '阻', '盘', '优', '丽', '家', '盘', '横', '怒', '行', '旧', '枪', '纪', '拽', '伊', '欢', '办', '有', '谢', '谢', '有', '还', '琴', '盘', '难', '这', '有', '盘', '藤', '些', '消', '盘', '产', '都', '思', '螂', '盘', '底', '熬', '客', '盘', '有', '昏', '题', '盘', '烛', '产', 'a', '很', '隐', '盘', '龙', '裂', '哈', '盘', '藤', '风', '潮', '盘', '欠', '护', '延', '旁', '墓', '昏', '有', '条', '快', '暴', '蒙', '大', '产', '昏', '爬', '醉', '爹', '喜', '盘', '玩', '望', '奔', '讽', '护', '延', '枯', '爹', '有', '血', '蛛', '盘', '吐', '痛', '折', '折', '乐', '着', '时', '练', '有', '托', '伊', '盘', '意', '大', '手', '秀', '灌', '有', '令', '歌', '狠', '旋', '穿', '盘', '才', '才', '形', '枪', '绪', '有', '鸠', '喜', '实', '盘', '扫', '下', '大', '欢', '拽', '宁', '昏', '果', '彿', '透', '起', '盘', '单', '瑰', '爽', '形', '枪', '有', '妈', '联', '盘', '正', '大', '产', '该', '植', '鳅', '荒', '敌', '有', '必', '坏', '狂', '狂', '袋', '温', '走', '银', '盘', '难', '这', '有', '盘', '藤', '些', '消', '盘', '产', '都', '思', '螂', '盘', '着', '底', '为', '盘', '有', '疼', '迎', '盘', '些', '决', '殿', '送', '忙', '盘', '龙', '再', '阻', '盘', '优', '丽', '家', '盘', '横', '怒', '行', '旧', '枪', '纪', '拽', '伊', '欢', '办', '有', '谢', '谢', '有', '还', '琴', '盘', '难', '这', '有', '盘', '藤', '些', '消', '盘', '产', '都', '思', '螂', '盘', '底', '熬', '客', '盘', '有', '昏', '题', '盘', '烛', '产', 'a', '很', '隐', '盘', '龙', '裂', '哈', '盘', '藤', '风', '潮', '盘', '欠', '护', '延', '旁', '墓', '昏', '有', '条', '快', '暴', '蒙', '大', '产', '昏', '爬', '醉', '爹', '喜', '盘', '玩', '望', '奔', '讽', '护', '延', '枯', '爹', '有', '血', '蛛', '盘', '吐', '痛', '折', '折', '乐', '着', '时', '练', '有', '托', '伊', '盘', '意', '大', '手', '秀', '灌', '有', '令', '歌', '狠', '旋', '穿', '盘', '才', '才', '形', '枪', '绪', '有', '鸠', '喜', '实', '盘', '扫', '下', '大', '欢', '拽', '宁', '昏', '果', '彿', '透', '起', '盘', '单', '瑰', '爽', '形', '枪', '有', '妈', '联', '盘', '正', '大', '产', '该', '植', '鳅', '荒', '敌', '有', '必', '坏', '狂', '狂', '袋', '温', '走', '银', '盘', '难', '这', '有', '盘', '藤', '些', '消', '盘', '产', '都', '思', '螂', '盘', '着', '底', '为', '盘', '有', '疼', '迎', '盘', '些', '决', '殿', '送', '忙', '盘', '龙', '再', '阻', '盘', '优', '丽', '家', '盘', '横', '怒', '行', '旧', '枪', '纪', '拽', '伊', '欢', '办', '有', '谢', '谢', '有', '还', '琴', '盘', '难', '这', '有', '盘', '藤', '些', '消', '盘', '产', '都', '思', '螂', '盘', '底', '熬', '客']\n"
     ]
    }
   ],
   "source": [
    "# 输出完整的一篇文章\n",
    "y_output=[]#final output\n",
    "init_x = [char_to_idx[char] for char in str100]\n",
    "for i in range(500):\n",
    "    x_test = np.array([init_x])\n",
    "    y_test = model2.predict_classes( x_test )\n",
    "    y_char = idx_to_char[y_test[0]]\n",
    "    y_output.append(y_char)\n",
    "    init_x = init_x[1:]\n",
    "    init_x.append(y_test[0])\n",
    "    \n",
    "print(y_output)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
