{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Import keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Create neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential() # 顺序模型\n",
    "\n",
    "# 输入层\n",
    "model.add(Dense(4, input_shape=(4,)))  # Dense就是常用的全连接层\n",
    "model.add(Activation('sigmoid')) # 激活函数\n",
    "\n",
    "# 隐层\n",
    "model.add(Dense(160))  # Dense就是常用的全连接层\n",
    "model.add(Activation('sigmoid')) # 激活函数\n",
    "\n",
    "# 输出层\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "150/150 [==============================] - 0s - loss: 1.2636 - acc: 0.3333     \n",
      "Epoch 2/500\n",
      "150/150 [==============================] - 0s - loss: 1.1295 - acc: 0.3333     \n",
      "Epoch 3/500\n",
      "150/150 [==============================] - 0s - loss: 1.0997 - acc: 0.3000     \n",
      "Epoch 4/500\n",
      "150/150 [==============================] - 0s - loss: 1.1092 - acc: 0.3333     \n",
      "Epoch 5/500\n",
      "150/150 [==============================] - 0s - loss: 1.1139 - acc: 0.3333     \n",
      "Epoch 6/500\n",
      "150/150 [==============================] - 0s - loss: 1.1029 - acc: 0.3333     \n",
      "Epoch 7/500\n",
      "150/150 [==============================] - 0s - loss: 1.0960 - acc: 0.4533     \n",
      "Epoch 8/500\n",
      "150/150 [==============================] - 0s - loss: 1.0937 - acc: 0.4000     \n",
      "Epoch 9/500\n",
      "150/150 [==============================] - 0s - loss: 1.0934 - acc: 0.3333     \n",
      "Epoch 10/500\n",
      "150/150 [==============================] - 0s - loss: 1.0942 - acc: 0.3333     \n",
      "Epoch 11/500\n",
      "150/150 [==============================] - 0s - loss: 1.0895 - acc: 0.4333     \n",
      "Epoch 12/500\n",
      "150/150 [==============================] - 0s - loss: 1.0869 - acc: 0.3333     \n",
      "Epoch 13/500\n",
      "150/150 [==============================] - 0s - loss: 1.0843 - acc: 0.4000     \n",
      "Epoch 14/500\n",
      "150/150 [==============================] - 0s - loss: 1.0810 - acc: 0.6667     \n",
      "Epoch 15/500\n",
      "150/150 [==============================] - 0s - loss: 1.0791 - acc: 0.5133     \n",
      "Epoch 16/500\n",
      "150/150 [==============================] - 0s - loss: 1.0764 - acc: 0.4933     \n",
      "Epoch 17/500\n",
      "150/150 [==============================] - 0s - loss: 1.0723 - acc: 0.6667     \n",
      "Epoch 18/500\n",
      "150/150 [==============================] - 0s - loss: 1.0676 - acc: 0.6800     \n",
      "Epoch 19/500\n",
      "150/150 [==============================] - 0s - loss: 1.0648 - acc: 0.5400     \n",
      "Epoch 20/500\n",
      "150/150 [==============================] - 0s - loss: 1.0561 - acc: 0.5400     \n",
      "Epoch 21/500\n",
      "150/150 [==============================] - 0s - loss: 1.0493 - acc: 0.6667     \n",
      "Epoch 22/500\n",
      "150/150 [==============================] - 0s - loss: 1.0452 - acc: 0.5933     \n",
      "Epoch 23/500\n",
      "150/150 [==============================] - 0s - loss: 1.0355 - acc: 0.6533     \n",
      "Epoch 24/500\n",
      "150/150 [==============================] - 0s - loss: 1.0268 - acc: 0.6667     \n",
      "Epoch 25/500\n",
      "150/150 [==============================] - 0s - loss: 1.0152 - acc: 0.6933     \n",
      "Epoch 26/500\n",
      "150/150 [==============================] - 0s - loss: 1.0034 - acc: 0.8800     \n",
      "Epoch 27/500\n",
      "150/150 [==============================] - 0s - loss: 0.9934 - acc: 0.7133     \n",
      "Epoch 28/500\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.9825 - acc: 0.812 - 0s - loss: 0.9831 - acc: 0.6667     \n",
      "Epoch 29/500\n",
      "150/150 [==============================] - 0s - loss: 0.9689 - acc: 0.6733     \n",
      "Epoch 30/500\n",
      "150/150 [==============================] - 0s - loss: 0.9539 - acc: 0.8067     \n",
      "Epoch 31/500\n",
      "150/150 [==============================] - 0s - loss: 0.9421 - acc: 0.8867     \n",
      "Epoch 32/500\n",
      "150/150 [==============================] - 0s - loss: 0.9260 - acc: 0.7400     \n",
      "Epoch 33/500\n",
      "150/150 [==============================] - 0s - loss: 0.9136 - acc: 0.8733     \n",
      "Epoch 34/500\n",
      "150/150 [==============================] - 0s - loss: 0.8994 - acc: 0.7733     \n",
      "Epoch 35/500\n",
      "150/150 [==============================] - 0s - loss: 0.8856 - acc: 0.7067     \n",
      "Epoch 36/500\n",
      "150/150 [==============================] - 0s - loss: 0.8722 - acc: 0.7000     \n",
      "Epoch 37/500\n",
      "150/150 [==============================] - 0s - loss: 0.8611 - acc: 0.6667     \n",
      "Epoch 38/500\n",
      "150/150 [==============================] - 0s - loss: 0.8453 - acc: 0.6667     \n",
      "Epoch 39/500\n",
      "150/150 [==============================] - 0s - loss: 0.8347 - acc: 0.8600     \n",
      "Epoch 40/500\n",
      "150/150 [==============================] - 0s - loss: 0.8199 - acc: 0.9467     \n",
      "Epoch 41/500\n",
      "150/150 [==============================] - 0s - loss: 0.8063 - acc: 0.7533     \n",
      "Epoch 42/500\n",
      "150/150 [==============================] - 0s - loss: 0.7928 - acc: 0.6667     \n",
      "Epoch 43/500\n",
      "150/150 [==============================] - 0s - loss: 0.7810 - acc: 0.7200     \n",
      "Epoch 44/500\n",
      "150/150 [==============================] - 0s - loss: 0.7662 - acc: 0.7200     \n",
      "Epoch 45/500\n",
      "150/150 [==============================] - 0s - loss: 0.7540 - acc: 0.7400     \n",
      "Epoch 46/500\n",
      "150/150 [==============================] - 0s - loss: 0.7419 - acc: 0.7000     \n",
      "Epoch 47/500\n",
      "150/150 [==============================] - 0s - loss: 0.7284 - acc: 0.6733     \n",
      "Epoch 48/500\n",
      "150/150 [==============================] - 0s - loss: 0.7160 - acc: 0.7133     \n",
      "Epoch 49/500\n",
      "150/150 [==============================] - 0s - loss: 0.7036 - acc: 0.7400     \n",
      "Epoch 50/500\n",
      "150/150 [==============================] - 0s - loss: 0.6916 - acc: 0.8200     \n",
      "Epoch 51/500\n",
      "150/150 [==============================] - 0s - loss: 0.6797 - acc: 0.8733     \n",
      "Epoch 52/500\n",
      "150/150 [==============================] - 0s - loss: 0.6692 - acc: 0.7800     \n",
      "Epoch 53/500\n",
      "150/150 [==============================] - 0s - loss: 0.6576 - acc: 0.7533     \n",
      "Epoch 54/500\n",
      "150/150 [==============================] - 0s - loss: 0.6469 - acc: 0.7533     \n",
      "Epoch 55/500\n",
      "150/150 [==============================] - 0s - loss: 0.6372 - acc: 0.7200     \n",
      "Epoch 56/500\n",
      "150/150 [==============================] - 0s - loss: 0.6263 - acc: 0.7200     \n",
      "Epoch 57/500\n",
      "150/150 [==============================] - 0s - loss: 0.6174 - acc: 0.8267     \n",
      "Epoch 58/500\n",
      "150/150 [==============================] - 0s - loss: 0.6075 - acc: 0.8867     \n",
      "Epoch 59/500\n",
      "150/150 [==============================] - 0s - loss: 0.5999 - acc: 0.8067     \n",
      "Epoch 60/500\n",
      "150/150 [==============================] - 0s - loss: 0.5903 - acc: 0.8000     \n",
      "Epoch 61/500\n",
      "150/150 [==============================] - 0s - loss: 0.5829 - acc: 0.8267     \n",
      "Epoch 62/500\n",
      "150/150 [==============================] - 0s - loss: 0.5741 - acc: 0.8733     \n",
      "Epoch 63/500\n",
      "150/150 [==============================] - 0s - loss: 0.5662 - acc: 0.9333     \n",
      "Epoch 64/500\n",
      "150/150 [==============================] - 0s - loss: 0.5598 - acc: 0.8400     \n",
      "Epoch 65/500\n",
      "150/150 [==============================] - 0s - loss: 0.5523 - acc: 0.8067     \n",
      "Epoch 66/500\n",
      "150/150 [==============================] - 0s - loss: 0.5463 - acc: 0.8600     \n",
      "Epoch 67/500\n",
      "150/150 [==============================] - 0s - loss: 0.5389 - acc: 0.8667     \n",
      "Epoch 68/500\n",
      "150/150 [==============================] - 0s - loss: 0.5325 - acc: 0.8267     \n",
      "Epoch 69/500\n",
      "150/150 [==============================] - 0s - loss: 0.5268 - acc: 0.8667     \n",
      "Epoch 70/500\n",
      "150/150 [==============================] - 0s - loss: 0.5209 - acc: 0.9067     \n",
      "Epoch 71/500\n",
      "150/150 [==============================] - 0s - loss: 0.5157 - acc: 0.9533     \n",
      "Epoch 72/500\n",
      "150/150 [==============================] - 0s - loss: 0.5115 - acc: 0.9733     \n",
      "Epoch 73/500\n",
      "150/150 [==============================] - 0s - loss: 0.5049 - acc: 0.9467     \n",
      "Epoch 74/500\n",
      "150/150 [==============================] - 0s - loss: 0.4990 - acc: 0.9067     \n",
      "Epoch 75/500\n",
      "150/150 [==============================] - 0s - loss: 0.4938 - acc: 0.9133     \n",
      "Epoch 76/500\n",
      "150/150 [==============================] - 0s - loss: 0.4893 - acc: 0.9200     \n",
      "Epoch 77/500\n",
      "150/150 [==============================] - 0s - loss: 0.4842 - acc: 0.9333     \n",
      "Epoch 78/500\n",
      "150/150 [==============================] - 0s - loss: 0.4800 - acc: 0.9667     \n",
      "Epoch 79/500\n",
      "150/150 [==============================] - 0s - loss: 0.4756 - acc: 0.9133     \n",
      "Epoch 80/500\n",
      "150/150 [==============================] - 0s - loss: 0.4709 - acc: 0.8800     \n",
      "Epoch 81/500\n",
      "150/150 [==============================] - 0s - loss: 0.4664 - acc: 0.9600     \n",
      "Epoch 82/500\n",
      "150/150 [==============================] - 0s - loss: 0.4620 - acc: 0.9667     \n",
      "Epoch 83/500\n",
      "150/150 [==============================] - 0s - loss: 0.4582 - acc: 0.9667     \n",
      "Epoch 84/500\n",
      "150/150 [==============================] - 0s - loss: 0.4529 - acc: 0.9667     \n",
      "Epoch 85/500\n",
      "150/150 [==============================] - 0s - loss: 0.4487 - acc: 0.9667     \n",
      "Epoch 86/500\n",
      "150/150 [==============================] - 0s - loss: 0.4451 - acc: 0.9667     \n",
      "Epoch 87/500\n",
      "150/150 [==============================] - 0s - loss: 0.4407 - acc: 0.9667     \n",
      "Epoch 88/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s - loss: 0.4378 - acc: 0.9467     \n",
      "Epoch 89/500\n",
      "150/150 [==============================] - 0s - loss: 0.4329 - acc: 0.9267     \n",
      "Epoch 90/500\n",
      "150/150 [==============================] - 0s - loss: 0.4278 - acc: 0.9600     \n",
      "Epoch 91/500\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.4095 - acc: 0.968 - 0s - loss: 0.4249 - acc: 0.9667     \n",
      "Epoch 92/500\n",
      "150/150 [==============================] - 0s - loss: 0.4212 - acc: 0.9800     \n",
      "Epoch 93/500\n",
      "150/150 [==============================] - 0s - loss: 0.4154 - acc: 0.9667     \n",
      "Epoch 94/500\n",
      "150/150 [==============================] - 0s - loss: 0.4119 - acc: 0.9667     \n",
      "Epoch 95/500\n",
      "150/150 [==============================] - 0s - loss: 0.4082 - acc: 0.9600     \n",
      "Epoch 96/500\n",
      "150/150 [==============================] - 0s - loss: 0.4037 - acc: 0.9667     \n",
      "Epoch 97/500\n",
      "150/150 [==============================] - 0s - loss: 0.4023 - acc: 0.9733     \n",
      "Epoch 98/500\n",
      "150/150 [==============================] - 0s - loss: 0.3971 - acc: 0.9667     \n",
      "Epoch 99/500\n",
      "150/150 [==============================] - 0s - loss: 0.3919 - acc: 0.9667     \n",
      "Epoch 100/500\n",
      "150/150 [==============================] - 0s - loss: 0.3875 - acc: 0.9667     \n",
      "Epoch 101/500\n",
      "150/150 [==============================] - 0s - loss: 0.3838 - acc: 0.9667     \n",
      "Epoch 102/500\n",
      "150/150 [==============================] - 0s - loss: 0.3791 - acc: 0.9667     \n",
      "Epoch 103/500\n",
      "150/150 [==============================] - 0s - loss: 0.3753 - acc: 0.9667     \n",
      "Epoch 104/500\n",
      "150/150 [==============================] - 0s - loss: 0.3720 - acc: 0.9667     \n",
      "Epoch 105/500\n",
      "150/150 [==============================] - 0s - loss: 0.3674 - acc: 0.9667     \n",
      "Epoch 106/500\n",
      "150/150 [==============================] - 0s - loss: 0.3643 - acc: 0.9667     \n",
      "Epoch 107/500\n",
      "150/150 [==============================] - 0s - loss: 0.3593 - acc: 0.9667     \n",
      "Epoch 108/500\n",
      "150/150 [==============================] - 0s - loss: 0.3564 - acc: 0.9667     \n",
      "Epoch 109/500\n",
      "150/150 [==============================] - 0s - loss: 0.3521 - acc: 0.9667     \n",
      "Epoch 110/500\n",
      "150/150 [==============================] - 0s - loss: 0.3484 - acc: 0.9667     \n",
      "Epoch 111/500\n",
      "150/150 [==============================] - 0s - loss: 0.3438 - acc: 0.9733     \n",
      "Epoch 112/500\n",
      "150/150 [==============================] - 0s - loss: 0.3392 - acc: 0.9667     \n",
      "Epoch 113/500\n",
      "150/150 [==============================] - 0s - loss: 0.3361 - acc: 0.9667     \n",
      "Epoch 114/500\n",
      "150/150 [==============================] - 0s - loss: 0.3323 - acc: 0.9667     \n",
      "Epoch 115/500\n",
      "150/150 [==============================] - 0s - loss: 0.3286 - acc: 0.9667     \n",
      "Epoch 116/500\n",
      "150/150 [==============================] - 0s - loss: 0.3249 - acc: 0.9667     \n",
      "Epoch 117/500\n",
      "150/150 [==============================] - 0s - loss: 0.3209 - acc: 0.9667     \n",
      "Epoch 118/500\n",
      "150/150 [==============================] - 0s - loss: 0.3170 - acc: 0.9667     \n",
      "Epoch 119/500\n",
      "150/150 [==============================] - 0s - loss: 0.3136 - acc: 0.9667     \n",
      "Epoch 120/500\n",
      "150/150 [==============================] - 0s - loss: 0.3096 - acc: 0.9733     \n",
      "Epoch 121/500\n",
      "150/150 [==============================] - 0s - loss: 0.3063 - acc: 0.9667     \n",
      "Epoch 122/500\n",
      "150/150 [==============================] - 0s - loss: 0.3030 - acc: 0.9667     \n",
      "Epoch 123/500\n",
      "150/150 [==============================] - 0s - loss: 0.2986 - acc: 0.9667     \n",
      "Epoch 124/500\n",
      "150/150 [==============================] - 0s - loss: 0.2950 - acc: 0.9667     \n",
      "Epoch 125/500\n",
      "150/150 [==============================] - 0s - loss: 0.2914 - acc: 0.9667     \n",
      "Epoch 126/500\n",
      "150/150 [==============================] - 0s - loss: 0.2878 - acc: 0.9667     \n",
      "Epoch 127/500\n",
      "150/150 [==============================] - 0s - loss: 0.2854 - acc: 0.9667     \n",
      "Epoch 128/500\n",
      "150/150 [==============================] - 0s - loss: 0.2816 - acc: 0.9733     \n",
      "Epoch 129/500\n",
      "150/150 [==============================] - 0s - loss: 0.2794 - acc: 0.9667     \n",
      "Epoch 130/500\n",
      "150/150 [==============================] - 0s - loss: 0.2749 - acc: 0.9733     \n",
      "Epoch 131/500\n",
      "150/150 [==============================] - 0s - loss: 0.2713 - acc: 0.9733     \n",
      "Epoch 132/500\n",
      "150/150 [==============================] - 0s - loss: 0.2679 - acc: 0.9733     \n",
      "Epoch 133/500\n",
      "150/150 [==============================] - 0s - loss: 0.2647 - acc: 0.9733     \n",
      "Epoch 134/500\n",
      "150/150 [==============================] - 0s - loss: 0.2620 - acc: 0.9667     \n",
      "Epoch 135/500\n",
      "150/150 [==============================] - 0s - loss: 0.2587 - acc: 0.9667     \n",
      "Epoch 136/500\n",
      "150/150 [==============================] - 0s - loss: 0.2551 - acc: 0.9667     \n",
      "Epoch 137/500\n",
      "150/150 [==============================] - 0s - loss: 0.2521 - acc: 0.9733     \n",
      "Epoch 138/500\n",
      "150/150 [==============================] - 0s - loss: 0.2493 - acc: 0.9733     \n",
      "Epoch 139/500\n",
      "150/150 [==============================] - 0s - loss: 0.2463 - acc: 0.9733     \n",
      "Epoch 140/500\n",
      "150/150 [==============================] - 0s - loss: 0.2437 - acc: 0.9733     \n",
      "Epoch 141/500\n",
      "150/150 [==============================] - 0s - loss: 0.2419 - acc: 0.9667     \n",
      "Epoch 142/500\n",
      "150/150 [==============================] - 0s - loss: 0.2375 - acc: 0.9667     \n",
      "Epoch 143/500\n",
      "150/150 [==============================] - 0s - loss: 0.2353 - acc: 0.9800     \n",
      "Epoch 144/500\n",
      "150/150 [==============================] - 0s - loss: 0.2324 - acc: 0.9733     \n",
      "Epoch 145/500\n",
      "150/150 [==============================] - 0s - loss: 0.2304 - acc: 0.9667     \n",
      "Epoch 146/500\n",
      "150/150 [==============================] - 0s - loss: 0.2270 - acc: 0.9667     \n",
      "Epoch 147/500\n",
      "150/150 [==============================] - 0s - loss: 0.2260 - acc: 0.9800     \n",
      "Epoch 148/500\n",
      "150/150 [==============================] - 0s - loss: 0.2224 - acc: 0.9733     \n",
      "Epoch 149/500\n",
      "150/150 [==============================] - 0s - loss: 0.2196 - acc: 0.9667     \n",
      "Epoch 150/500\n",
      "150/150 [==============================] - 0s - loss: 0.2172 - acc: 0.9667     \n",
      "Epoch 151/500\n",
      "150/150 [==============================] - 0s - loss: 0.2146 - acc: 0.9733     \n",
      "Epoch 152/500\n",
      "150/150 [==============================] - 0s - loss: 0.2124 - acc: 0.9733     \n",
      "Epoch 153/500\n",
      "150/150 [==============================] - 0s - loss: 0.2099 - acc: 0.9733     \n",
      "Epoch 154/500\n",
      "150/150 [==============================] - 0s - loss: 0.2078 - acc: 0.9733     \n",
      "Epoch 155/500\n",
      "150/150 [==============================] - 0s - loss: 0.2058 - acc: 0.9667     \n",
      "Epoch 156/500\n",
      "150/150 [==============================] - 0s - loss: 0.2025 - acc: 0.9733     \n",
      "Epoch 157/500\n",
      "150/150 [==============================] - 0s - loss: 0.2008 - acc: 0.9733     \n",
      "Epoch 158/500\n",
      "150/150 [==============================] - 0s - loss: 0.1991 - acc: 0.9733     \n",
      "Epoch 159/500\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2122 - acc: 0.906 - 0s - loss: 0.1963 - acc: 0.9733     \n",
      "Epoch 160/500\n",
      "150/150 [==============================] - 0s - loss: 0.1950 - acc: 0.9733     \n",
      "Epoch 161/500\n",
      "150/150 [==============================] - 0s - loss: 0.1922 - acc: 0.9667     \n",
      "Epoch 162/500\n",
      "150/150 [==============================] - 0s - loss: 0.1913 - acc: 0.9800     \n",
      "Epoch 163/500\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1643 - acc: 1.000 - 0s - loss: 0.1889 - acc: 0.9733     \n",
      "Epoch 164/500\n",
      "150/150 [==============================] - 0s - loss: 0.1863 - acc: 0.9733     \n",
      "Epoch 165/500\n",
      "150/150 [==============================] - 0s - loss: 0.1845 - acc: 0.9733     \n",
      "Epoch 166/500\n",
      "150/150 [==============================] - 0s - loss: 0.1827 - acc: 0.9733     \n",
      "Epoch 167/500\n",
      "150/150 [==============================] - 0s - loss: 0.1810 - acc: 0.9733     \n",
      "Epoch 168/500\n",
      "150/150 [==============================] - 0s - loss: 0.1789 - acc: 0.9733     \n",
      "Epoch 169/500\n",
      "150/150 [==============================] - 0s - loss: 0.1770 - acc: 0.9733     \n",
      "Epoch 170/500\n",
      "150/150 [==============================] - 0s - loss: 0.1756 - acc: 0.9733     \n",
      "Epoch 171/500\n",
      "150/150 [==============================] - 0s - loss: 0.1741 - acc: 0.9733     \n",
      "Epoch 172/500\n",
      "150/150 [==============================] - 0s - loss: 0.1723 - acc: 0.9733     \n",
      "Epoch 173/500\n",
      "150/150 [==============================] - 0s - loss: 0.1708 - acc: 0.9733     \n",
      "Epoch 174/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s - loss: 0.1686 - acc: 0.9733     \n",
      "Epoch 175/500\n",
      "150/150 [==============================] - 0s - loss: 0.1675 - acc: 0.9733     \n",
      "Epoch 176/500\n",
      "150/150 [==============================] - 0s - loss: 0.1657 - acc: 0.9733     \n",
      "Epoch 177/500\n",
      "150/150 [==============================] - 0s - loss: 0.1647 - acc: 0.9733     \n",
      "Epoch 178/500\n",
      "150/150 [==============================] - 0s - loss: 0.1626 - acc: 0.9733     \n",
      "Epoch 179/500\n",
      "150/150 [==============================] - 0s - loss: 0.1620 - acc: 0.9733     \n",
      "Epoch 180/500\n",
      "150/150 [==============================] - 0s - loss: 0.1605 - acc: 0.9667     \n",
      "Epoch 181/500\n",
      "150/150 [==============================] - 0s - loss: 0.1589 - acc: 0.9667     \n",
      "Epoch 182/500\n",
      "150/150 [==============================] - 0s - loss: 0.1566 - acc: 0.9733     \n",
      "Epoch 183/500\n",
      "150/150 [==============================] - 0s - loss: 0.1571 - acc: 0.9733     \n",
      "Epoch 184/500\n",
      "150/150 [==============================] - 0s - loss: 0.1557 - acc: 0.9733     \n",
      "Epoch 185/500\n",
      "150/150 [==============================] - 0s - loss: 0.1532 - acc: 0.9733     \n",
      "Epoch 186/500\n",
      "150/150 [==============================] - 0s - loss: 0.1521 - acc: 0.9733     \n",
      "Epoch 187/500\n",
      "150/150 [==============================] - 0s - loss: 0.1494 - acc: 0.9733     \n",
      "Epoch 188/500\n",
      "150/150 [==============================] - 0s - loss: 0.1533 - acc: 0.9667     \n",
      "Epoch 189/500\n",
      "150/150 [==============================] - 0s - loss: 0.1491 - acc: 0.9733     \n",
      "Epoch 190/500\n",
      "150/150 [==============================] - 0s - loss: 0.1479 - acc: 0.9733     \n",
      "Epoch 191/500\n",
      "150/150 [==============================] - 0s - loss: 0.1461 - acc: 0.9733     \n",
      "Epoch 192/500\n",
      "150/150 [==============================] - 0s - loss: 0.1443 - acc: 0.9733     \n",
      "Epoch 193/500\n",
      "150/150 [==============================] - 0s - loss: 0.1429 - acc: 0.9733     \n",
      "Epoch 194/500\n",
      "150/150 [==============================] - 0s - loss: 0.1419 - acc: 0.9733     \n",
      "Epoch 195/500\n",
      "150/150 [==============================] - 0s - loss: 0.1415 - acc: 0.9733     \n",
      "Epoch 196/500\n",
      "150/150 [==============================] - 0s - loss: 0.1396 - acc: 0.9800     \n",
      "Epoch 197/500\n",
      "150/150 [==============================] - 0s - loss: 0.1392 - acc: 0.9733     \n",
      "Epoch 198/500\n",
      "150/150 [==============================] - 0s - loss: 0.1377 - acc: 0.9800     \n",
      "Epoch 199/500\n",
      "150/150 [==============================] - 0s - loss: 0.1362 - acc: 0.9733     \n",
      "Epoch 200/500\n",
      "150/150 [==============================] - 0s - loss: 0.1355 - acc: 0.9733     \n",
      "Epoch 201/500\n",
      "150/150 [==============================] - 0s - loss: 0.1350 - acc: 0.9733     \n",
      "Epoch 202/500\n",
      "150/150 [==============================] - 0s - loss: 0.1337 - acc: 0.9733     \n",
      "Epoch 203/500\n",
      "150/150 [==============================] - 0s - loss: 0.1328 - acc: 0.9733     \n",
      "Epoch 204/500\n",
      "150/150 [==============================] - 0s - loss: 0.1317 - acc: 0.9733     \n",
      "Epoch 205/500\n",
      "150/150 [==============================] - 0s - loss: 0.1309 - acc: 0.9733     \n",
      "Epoch 206/500\n",
      "150/150 [==============================] - 0s - loss: 0.1306 - acc: 0.9733     \n",
      "Epoch 207/500\n",
      "150/150 [==============================] - 0s - loss: 0.1301 - acc: 0.9667     \n",
      "Epoch 208/500\n",
      "150/150 [==============================] - 0s - loss: 0.1278 - acc: 0.9733     \n",
      "Epoch 209/500\n",
      "150/150 [==============================] - 0s - loss: 0.1280 - acc: 0.9733     \n",
      "Epoch 210/500\n",
      "150/150 [==============================] - 0s - loss: 0.1267 - acc: 0.9733     \n",
      "Epoch 211/500\n",
      "150/150 [==============================] - 0s - loss: 0.1254 - acc: 0.9733     \n",
      "Epoch 212/500\n",
      "150/150 [==============================] - 0s - loss: 0.1249 - acc: 0.9733     \n",
      "Epoch 213/500\n",
      "150/150 [==============================] - 0s - loss: 0.1237 - acc: 0.9733     \n",
      "Epoch 214/500\n",
      "150/150 [==============================] - 0s - loss: 0.1235 - acc: 0.9733     \n",
      "Epoch 215/500\n",
      "150/150 [==============================] - 0s - loss: 0.1224 - acc: 0.9733     \n",
      "Epoch 216/500\n",
      "150/150 [==============================] - 0s - loss: 0.1217 - acc: 0.9733     \n",
      "Epoch 217/500\n",
      "150/150 [==============================] - 0s - loss: 0.1212 - acc: 0.9733     \n",
      "Epoch 218/500\n",
      "150/150 [==============================] - 0s - loss: 0.1197 - acc: 0.9733     \n",
      "Epoch 219/500\n",
      "150/150 [==============================] - 0s - loss: 0.1192 - acc: 0.9733     \n",
      "Epoch 220/500\n",
      "150/150 [==============================] - 0s - loss: 0.1184 - acc: 0.9733     \n",
      "Epoch 221/500\n",
      "150/150 [==============================] - 0s - loss: 0.1176 - acc: 0.9733     \n",
      "Epoch 222/500\n",
      "150/150 [==============================] - 0s - loss: 0.1168 - acc: 0.9733     \n",
      "Epoch 223/500\n",
      "150/150 [==============================] - 0s - loss: 0.1163 - acc: 0.9733     \n",
      "Epoch 224/500\n",
      "150/150 [==============================] - 0s - loss: 0.1157 - acc: 0.9733     \n",
      "Epoch 225/500\n",
      "150/150 [==============================] - 0s - loss: 0.1162 - acc: 0.9733     \n",
      "Epoch 226/500\n",
      "150/150 [==============================] - 0s - loss: 0.1144 - acc: 0.9733     \n",
      "Epoch 227/500\n",
      "150/150 [==============================] - 0s - loss: 0.1147 - acc: 0.9733     \n",
      "Epoch 228/500\n",
      "150/150 [==============================] - 0s - loss: 0.1147 - acc: 0.9733     \n",
      "Epoch 229/500\n",
      "150/150 [==============================] - 0s - loss: 0.1115 - acc: 0.9733     \n",
      "Epoch 230/500\n",
      "150/150 [==============================] - 0s - loss: 0.1146 - acc: 0.9733     \n",
      "Epoch 231/500\n",
      "150/150 [==============================] - 0s - loss: 0.1123 - acc: 0.9733     \n",
      "Epoch 232/500\n",
      "150/150 [==============================] - 0s - loss: 0.1114 - acc: 0.9733     \n",
      "Epoch 233/500\n",
      "150/150 [==============================] - 0s - loss: 0.1106 - acc: 0.9733     \n",
      "Epoch 234/500\n",
      "150/150 [==============================] - 0s - loss: 0.1092 - acc: 0.9733     \n",
      "Epoch 235/500\n",
      "150/150 [==============================] - 0s - loss: 0.1094 - acc: 0.9733     \n",
      "Epoch 236/500\n",
      "150/150 [==============================] - 0s - loss: 0.1080 - acc: 0.9733     \n",
      "Epoch 237/500\n",
      "150/150 [==============================] - 0s - loss: 0.1072 - acc: 0.9733     \n",
      "Epoch 238/500\n",
      "150/150 [==============================] - 0s - loss: 0.1073 - acc: 0.9733     \n",
      "Epoch 239/500\n",
      "150/150 [==============================] - 0s - loss: 0.1066 - acc: 0.9733     \n",
      "Epoch 240/500\n",
      "150/150 [==============================] - 0s - loss: 0.1056 - acc: 0.9733     \n",
      "Epoch 241/500\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0961 - acc: 1.000 - 0s - loss: 0.1055 - acc: 0.9733     \n",
      "Epoch 242/500\n",
      "150/150 [==============================] - 0s - loss: 0.1049 - acc: 0.9733     \n",
      "Epoch 243/500\n",
      "150/150 [==============================] - 0s - loss: 0.1042 - acc: 0.9733     \n",
      "Epoch 244/500\n",
      "150/150 [==============================] - 0s - loss: 0.1040 - acc: 0.9733     \n",
      "Epoch 245/500\n",
      "150/150 [==============================] - 0s - loss: 0.1031 - acc: 0.9733     \n",
      "Epoch 246/500\n",
      "150/150 [==============================] - 0s - loss: 0.1026 - acc: 0.9733     \n",
      "Epoch 247/500\n",
      "150/150 [==============================] - 0s - loss: 0.1026 - acc: 0.9733     \n",
      "Epoch 248/500\n",
      "150/150 [==============================] - 0s - loss: 0.1021 - acc: 0.9733     \n",
      "Epoch 249/500\n",
      "150/150 [==============================] - 0s - loss: 0.1023 - acc: 0.9733     \n",
      "Epoch 250/500\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0751 - acc: 1.000 - 0s - loss: 0.1008 - acc: 0.9733     \n",
      "Epoch 251/500\n",
      "150/150 [==============================] - 0s - loss: 0.1003 - acc: 0.9733     \n",
      "Epoch 252/500\n",
      "150/150 [==============================] - 0s - loss: 0.1000 - acc: 0.9733     \n",
      "Epoch 253/500\n",
      "150/150 [==============================] - 0s - loss: 0.0995 - acc: 0.9733     \n",
      "Epoch 254/500\n",
      "150/150 [==============================] - 0s - loss: 0.0988 - acc: 0.9733     \n",
      "Epoch 255/500\n",
      "150/150 [==============================] - 0s - loss: 0.0989 - acc: 0.9733     \n",
      "Epoch 256/500\n",
      "150/150 [==============================] - 0s - loss: 0.0992 - acc: 0.9733     \n",
      "Epoch 257/500\n",
      "150/150 [==============================] - 0s - loss: 0.0981 - acc: 0.9733     \n",
      "Epoch 258/500\n",
      "150/150 [==============================] - 0s - loss: 0.0974 - acc: 0.9733     \n",
      "Epoch 259/500\n",
      "150/150 [==============================] - 0s - loss: 0.0968 - acc: 0.9733     \n",
      "Epoch 260/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s - loss: 0.0966 - acc: 0.9733     \n",
      "Epoch 261/500\n",
      "150/150 [==============================] - 0s - loss: 0.0962 - acc: 0.9733     \n",
      "Epoch 262/500\n",
      "150/150 [==============================] - 0s - loss: 0.0956 - acc: 0.9800     \n",
      "Epoch 263/500\n",
      "150/150 [==============================] - 0s - loss: 0.0952 - acc: 0.9733     \n",
      "Epoch 264/500\n",
      "150/150 [==============================] - 0s - loss: 0.0950 - acc: 0.9733     \n",
      "Epoch 265/500\n",
      "150/150 [==============================] - 0s - loss: 0.0949 - acc: 0.9733     \n",
      "Epoch 266/500\n",
      "150/150 [==============================] - 0s - loss: 0.0958 - acc: 0.9733     \n",
      "Epoch 267/500\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1322 - acc: 0.968 - 0s - loss: 0.0934 - acc: 0.9733     \n",
      "Epoch 268/500\n",
      "150/150 [==============================] - 0s - loss: 0.0930 - acc: 0.9733     \n",
      "Epoch 269/500\n",
      "150/150 [==============================] - 0s - loss: 0.0932 - acc: 0.9733     \n",
      "Epoch 270/500\n",
      "150/150 [==============================] - 0s - loss: 0.0928 - acc: 0.9733     \n",
      "Epoch 271/500\n",
      "150/150 [==============================] - 0s - loss: 0.0921 - acc: 0.9733     \n",
      "Epoch 272/500\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1429 - acc: 0.906 - 0s - loss: 0.0942 - acc: 0.9733     \n",
      "Epoch 273/500\n",
      "150/150 [==============================] - 0s - loss: 0.0921 - acc: 0.9733     \n",
      "Epoch 274/500\n",
      "150/150 [==============================] - 0s - loss: 0.0915 - acc: 0.9800     \n",
      "Epoch 275/500\n",
      "150/150 [==============================] - 0s - loss: 0.0912 - acc: 0.9733     \n",
      "Epoch 276/500\n",
      "150/150 [==============================] - 0s - loss: 0.0907 - acc: 0.9733     \n",
      "Epoch 277/500\n",
      "150/150 [==============================] - 0s - loss: 0.0903 - acc: 0.9733     \n",
      "Epoch 278/500\n",
      "150/150 [==============================] - 0s - loss: 0.0915 - acc: 0.9733     \n",
      "Epoch 279/500\n",
      "150/150 [==============================] - 0s - loss: 0.0894 - acc: 0.9733     \n",
      "Epoch 280/500\n",
      "150/150 [==============================] - 0s - loss: 0.0888 - acc: 0.9733     \n",
      "Epoch 281/500\n",
      "150/150 [==============================] - 0s - loss: 0.0889 - acc: 0.9733     \n",
      "Epoch 282/500\n",
      "150/150 [==============================] - 0s - loss: 0.0893 - acc: 0.9733     \n",
      "Epoch 283/500\n",
      "150/150 [==============================] - 0s - loss: 0.0879 - acc: 0.9733     \n",
      "Epoch 284/500\n",
      "150/150 [==============================] - 0s - loss: 0.0875 - acc: 0.9733     \n",
      "Epoch 285/500\n",
      "150/150 [==============================] - 0s - loss: 0.0888 - acc: 0.9733     \n",
      "Epoch 286/500\n",
      "150/150 [==============================] - 0s - loss: 0.0895 - acc: 0.9667     \n",
      "Epoch 287/500\n",
      "150/150 [==============================] - 0s - loss: 0.0874 - acc: 0.9733     \n",
      "Epoch 288/500\n",
      "150/150 [==============================] - 0s - loss: 0.0868 - acc: 0.9733     \n",
      "Epoch 289/500\n",
      "150/150 [==============================] - 0s - loss: 0.0860 - acc: 0.9733     \n",
      "Epoch 290/500\n",
      "150/150 [==============================] - 0s - loss: 0.0863 - acc: 0.9733     \n",
      "Epoch 291/500\n",
      "150/150 [==============================] - 0s - loss: 0.0863 - acc: 0.9733     \n",
      "Epoch 292/500\n",
      "150/150 [==============================] - 0s - loss: 0.0855 - acc: 0.9733     \n",
      "Epoch 293/500\n",
      "150/150 [==============================] - 0s - loss: 0.0852 - acc: 0.9733     \n",
      "Epoch 294/500\n",
      "150/150 [==============================] - 0s - loss: 0.0851 - acc: 0.9733     \n",
      "Epoch 295/500\n",
      "150/150 [==============================] - 0s - loss: 0.0850 - acc: 0.9733     \n",
      "Epoch 296/500\n",
      "150/150 [==============================] - 0s - loss: 0.0845 - acc: 0.9733     \n",
      "Epoch 297/500\n",
      "150/150 [==============================] - 0s - loss: 0.0845 - acc: 0.9733     \n",
      "Epoch 298/500\n",
      "150/150 [==============================] - 0s - loss: 0.0846 - acc: 0.9733     \n",
      "Epoch 299/500\n",
      "150/150 [==============================] - 0s - loss: 0.0844 - acc: 0.9733     \n",
      "Epoch 300/500\n",
      "150/150 [==============================] - 0s - loss: 0.0849 - acc: 0.9733     \n",
      "Epoch 301/500\n",
      "150/150 [==============================] - 0s - loss: 0.0830 - acc: 0.9733     \n",
      "Epoch 302/500\n",
      "150/150 [==============================] - 0s - loss: 0.0838 - acc: 0.9733     \n",
      "Epoch 303/500\n",
      "150/150 [==============================] - 0s - loss: 0.0834 - acc: 0.9733     \n",
      "Epoch 304/500\n",
      "150/150 [==============================] - 0s - loss: 0.0824 - acc: 0.9733     \n",
      "Epoch 305/500\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0715 - acc: 0.968 - 0s - loss: 0.0825 - acc: 0.9733     \n",
      "Epoch 306/500\n",
      "150/150 [==============================] - 0s - loss: 0.0825 - acc: 0.9733     \n",
      "Epoch 307/500\n",
      "150/150 [==============================] - 0s - loss: 0.0825 - acc: 0.9733     \n",
      "Epoch 308/500\n",
      "150/150 [==============================] - 0s - loss: 0.0820 - acc: 0.9667     \n",
      "Epoch 309/500\n",
      "150/150 [==============================] - 0s - loss: 0.0816 - acc: 0.9733     \n",
      "Epoch 310/500\n",
      "150/150 [==============================] - 0s - loss: 0.0817 - acc: 0.9733     \n",
      "Epoch 311/500\n",
      "150/150 [==============================] - 0s - loss: 0.0810 - acc: 0.9733     \n",
      "Epoch 312/500\n",
      "150/150 [==============================] - 0s - loss: 0.0810 - acc: 0.9733     \n",
      "Epoch 313/500\n",
      "150/150 [==============================] - 0s - loss: 0.0808 - acc: 0.9733     \n",
      "Epoch 314/500\n",
      "150/150 [==============================] - 0s - loss: 0.0804 - acc: 0.9733     \n",
      "Epoch 315/500\n",
      "150/150 [==============================] - 0s - loss: 0.0812 - acc: 0.9667     \n",
      "Epoch 316/500\n",
      "150/150 [==============================] - 0s - loss: 0.0808 - acc: 0.9733     \n",
      "Epoch 317/500\n",
      "150/150 [==============================] - 0s - loss: 0.0800 - acc: 0.9800     \n",
      "Epoch 318/500\n",
      "150/150 [==============================] - 0s - loss: 0.0795 - acc: 0.9733     \n",
      "Epoch 319/500\n",
      "150/150 [==============================] - 0s - loss: 0.0792 - acc: 0.9733     \n",
      "Epoch 320/500\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0689 - acc: 1.000 - 0s - loss: 0.0788 - acc: 0.9733     \n",
      "Epoch 321/500\n",
      "150/150 [==============================] - 0s - loss: 0.0789 - acc: 0.9667     \n",
      "Epoch 322/500\n",
      "150/150 [==============================] - 0s - loss: 0.0782 - acc: 0.9733     \n",
      "Epoch 323/500\n",
      "150/150 [==============================] - 0s - loss: 0.0785 - acc: 0.9667     \n",
      "Epoch 324/500\n",
      "150/150 [==============================] - 0s - loss: 0.0779 - acc: 0.9667     \n",
      "Epoch 325/500\n",
      "150/150 [==============================] - 0s - loss: 0.0789 - acc: 0.9667     \n",
      "Epoch 326/500\n",
      "150/150 [==============================] - 0s - loss: 0.0782 - acc: 0.9667     \n",
      "Epoch 327/500\n",
      "150/150 [==============================] - 0s - loss: 0.0791 - acc: 0.9733     \n",
      "Epoch 328/500\n",
      "150/150 [==============================] - 0s - loss: 0.0774 - acc: 0.9733     \n",
      "Epoch 329/500\n",
      "150/150 [==============================] - 0s - loss: 0.0774 - acc: 0.9667     \n",
      "Epoch 330/500\n",
      "150/150 [==============================] - 0s - loss: 0.0778 - acc: 0.9733     \n",
      "Epoch 331/500\n",
      "150/150 [==============================] - 0s - loss: 0.0767 - acc: 0.9733     \n",
      "Epoch 332/500\n",
      "150/150 [==============================] - 0s - loss: 0.0764 - acc: 0.9733     \n",
      "Epoch 333/500\n",
      "150/150 [==============================] - 0s - loss: 0.0763 - acc: 0.9733     \n",
      "Epoch 334/500\n",
      "150/150 [==============================] - 0s - loss: 0.0765 - acc: 0.9733     \n",
      "Epoch 335/500\n",
      "150/150 [==============================] - 0s - loss: 0.0759 - acc: 0.9733     \n",
      "Epoch 336/500\n",
      "150/150 [==============================] - 0s - loss: 0.0762 - acc: 0.9733     \n",
      "Epoch 337/500\n",
      "150/150 [==============================] - 0s - loss: 0.0758 - acc: 0.9667     \n",
      "Epoch 338/500\n",
      "150/150 [==============================] - 0s - loss: 0.0754 - acc: 0.9733     \n",
      "Epoch 339/500\n",
      "150/150 [==============================] - 0s - loss: 0.0752 - acc: 0.9667     \n",
      "Epoch 340/500\n",
      "150/150 [==============================] - 0s - loss: 0.0753 - acc: 0.9733     \n",
      "Epoch 341/500\n",
      "150/150 [==============================] - 0s - loss: 0.0753 - acc: 0.9667     \n",
      "Epoch 342/500\n",
      "150/150 [==============================] - 0s - loss: 0.0746 - acc: 0.9733     \n",
      "Epoch 343/500\n",
      "150/150 [==============================] - 0s - loss: 0.0747 - acc: 0.9733     \n",
      "Epoch 344/500\n",
      "150/150 [==============================] - 0s - loss: 0.0749 - acc: 0.9733     \n",
      "Epoch 345/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s - loss: 0.0741 - acc: 0.9733     \n",
      "Epoch 346/500\n",
      "150/150 [==============================] - 0s - loss: 0.0740 - acc: 0.9733     \n",
      "Epoch 347/500\n",
      "150/150 [==============================] - 0s - loss: 0.0741 - acc: 0.9733     \n",
      "Epoch 348/500\n",
      "150/150 [==============================] - 0s - loss: 0.0738 - acc: 0.9733     \n",
      "Epoch 349/500\n",
      "150/150 [==============================] - 0s - loss: 0.0749 - acc: 0.9667     \n",
      "Epoch 350/500\n",
      "150/150 [==============================] - 0s - loss: 0.0735 - acc: 0.9733     \n",
      "Epoch 351/500\n",
      "150/150 [==============================] - 0s - loss: 0.0732 - acc: 0.9667     \n",
      "Epoch 352/500\n",
      "150/150 [==============================] - 0s - loss: 0.0737 - acc: 0.9733     \n",
      "Epoch 353/500\n",
      "150/150 [==============================] - 0s - loss: 0.0730 - acc: 0.9733     \n",
      "Epoch 354/500\n",
      "150/150 [==============================] - 0s - loss: 0.0728 - acc: 0.9733     \n",
      "Epoch 355/500\n",
      "150/150 [==============================] - 0s - loss: 0.0728 - acc: 0.9667     \n",
      "Epoch 356/500\n",
      "150/150 [==============================] - 0s - loss: 0.0733 - acc: 0.9733     \n",
      "Epoch 357/500\n",
      "150/150 [==============================] - 0s - loss: 0.0745 - acc: 0.9667     \n",
      "Epoch 358/500\n",
      "150/150 [==============================] - 0s - loss: 0.0723 - acc: 0.9733     \n",
      "Epoch 359/500\n",
      "150/150 [==============================] - 0s - loss: 0.0719 - acc: 0.9733     \n",
      "Epoch 360/500\n",
      "150/150 [==============================] - 0s - loss: 0.0721 - acc: 0.9733     \n",
      "Epoch 361/500\n",
      "150/150 [==============================] - 0s - loss: 0.0723 - acc: 0.9733     \n",
      "Epoch 362/500\n",
      "150/150 [==============================] - 0s - loss: 0.0713 - acc: 0.9733     \n",
      "Epoch 363/500\n",
      "150/150 [==============================] - 0s - loss: 0.0713 - acc: 0.9733     \n",
      "Epoch 364/500\n",
      "150/150 [==============================] - 0s - loss: 0.0716 - acc: 0.9733     \n",
      "Epoch 365/500\n",
      "150/150 [==============================] - 0s - loss: 0.0720 - acc: 0.9733     \n",
      "Epoch 366/500\n",
      "150/150 [==============================] - 0s - loss: 0.0712 - acc: 0.9733     \n",
      "Epoch 367/500\n",
      "150/150 [==============================] - 0s - loss: 0.0710 - acc: 0.9733     \n",
      "Epoch 368/500\n",
      "150/150 [==============================] - 0s - loss: 0.0710 - acc: 0.9733     \n",
      "Epoch 369/500\n",
      "150/150 [==============================] - 0s - loss: 0.0709 - acc: 0.9733     \n",
      "Epoch 370/500\n",
      "150/150 [==============================] - 0s - loss: 0.0704 - acc: 0.9667     \n",
      "Epoch 371/500\n",
      "150/150 [==============================] - 0s - loss: 0.0702 - acc: 0.9733     \n",
      "Epoch 372/500\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0553 - acc: 0.968 - 0s - loss: 0.0706 - acc: 0.9733     \n",
      "Epoch 373/500\n",
      "150/150 [==============================] - 0s - loss: 0.0704 - acc: 0.9733     \n",
      "Epoch 374/500\n",
      "150/150 [==============================] - 0s - loss: 0.0700 - acc: 0.9733     \n",
      "Epoch 375/500\n",
      "150/150 [==============================] - 0s - loss: 0.0698 - acc: 0.9733     \n",
      "Epoch 376/500\n",
      "150/150 [==============================] - 0s - loss: 0.0700 - acc: 0.9667     \n",
      "Epoch 377/500\n",
      "150/150 [==============================] - 0s - loss: 0.0698 - acc: 0.9733     \n",
      "Epoch 378/500\n",
      "150/150 [==============================] - 0s - loss: 0.0697 - acc: 0.9733     \n",
      "Epoch 379/500\n",
      "150/150 [==============================] - 0s - loss: 0.0692 - acc: 0.9733     \n",
      "Epoch 380/500\n",
      "150/150 [==============================] - 0s - loss: 0.0700 - acc: 0.9733     \n",
      "Epoch 381/500\n",
      "150/150 [==============================] - 0s - loss: 0.0691 - acc: 0.9667     \n",
      "Epoch 382/500\n",
      "150/150 [==============================] - 0s - loss: 0.0697 - acc: 0.9733     \n",
      "Epoch 383/500\n",
      "150/150 [==============================] - 0s - loss: 0.0701 - acc: 0.9733     \n",
      "Epoch 384/500\n",
      "150/150 [==============================] - 0s - loss: 0.0687 - acc: 0.9733     \n",
      "Epoch 385/500\n",
      "150/150 [==============================] - 0s - loss: 0.0691 - acc: 0.9800     \n",
      "Epoch 386/500\n",
      "150/150 [==============================] - 0s - loss: 0.0687 - acc: 0.9733     \n",
      "Epoch 387/500\n",
      "150/150 [==============================] - 0s - loss: 0.0683 - acc: 0.9733     \n",
      "Epoch 388/500\n",
      "150/150 [==============================] - 0s - loss: 0.0684 - acc: 0.9667     \n",
      "Epoch 389/500\n",
      "150/150 [==============================] - 0s - loss: 0.0683 - acc: 0.9733     \n",
      "Epoch 390/500\n",
      "150/150 [==============================] - 0s - loss: 0.0682 - acc: 0.9667     \n",
      "Epoch 391/500\n",
      "150/150 [==============================] - 0s - loss: 0.0680 - acc: 0.9733     \n",
      "Epoch 392/500\n",
      "150/150 [==============================] - 0s - loss: 0.0685 - acc: 0.9733     \n",
      "Epoch 393/500\n",
      "150/150 [==============================] - 0s - loss: 0.0684 - acc: 0.9800     \n",
      "Epoch 394/500\n",
      "150/150 [==============================] - 0s - loss: 0.0677 - acc: 0.9667     \n",
      "Epoch 395/500\n",
      "150/150 [==============================] - 0s - loss: 0.0676 - acc: 0.9667     \n",
      "Epoch 396/500\n",
      "150/150 [==============================] - 0s - loss: 0.0674 - acc: 0.9733     \n",
      "Epoch 397/500\n",
      "150/150 [==============================] - 0s - loss: 0.0673 - acc: 0.9733     \n",
      "Epoch 398/500\n",
      "150/150 [==============================] - 0s - loss: 0.0681 - acc: 0.9667     \n",
      "Epoch 399/500\n",
      "150/150 [==============================] - 0s - loss: 0.0670 - acc: 0.9667     \n",
      "Epoch 400/500\n",
      "150/150 [==============================] - 0s - loss: 0.0670 - acc: 0.9733     \n",
      "Epoch 401/500\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0268 - acc: 1.000 - 0s - loss: 0.0676 - acc: 0.9733     \n",
      "Epoch 402/500\n",
      "150/150 [==============================] - 0s - loss: 0.0668 - acc: 0.9667     \n",
      "Epoch 403/500\n",
      "150/150 [==============================] - 0s - loss: 0.0666 - acc: 0.9667     \n",
      "Epoch 404/500\n",
      "150/150 [==============================] - 0s - loss: 0.0671 - acc: 0.9667     \n",
      "Epoch 405/500\n",
      "150/150 [==============================] - 0s - loss: 0.0665 - acc: 0.9733     \n",
      "Epoch 406/500\n",
      "150/150 [==============================] - 0s - loss: 0.0663 - acc: 0.9733     \n",
      "Epoch 407/500\n",
      "150/150 [==============================] - 0s - loss: 0.0665 - acc: 0.9733     \n",
      "Epoch 408/500\n",
      "150/150 [==============================] - 0s - loss: 0.0664 - acc: 0.9733     \n",
      "Epoch 409/500\n",
      "150/150 [==============================] - 0s - loss: 0.0661 - acc: 0.9733     \n",
      "Epoch 410/500\n",
      "150/150 [==============================] - 0s - loss: 0.0666 - acc: 0.9733     \n",
      "Epoch 411/500\n",
      "150/150 [==============================] - 0s - loss: 0.0666 - acc: 0.9667     \n",
      "Epoch 412/500\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0528 - acc: 1.000 - 0s - loss: 0.0667 - acc: 0.9733     \n",
      "Epoch 413/500\n",
      "150/150 [==============================] - 0s - loss: 0.0651 - acc: 0.9733     \n",
      "Epoch 414/500\n",
      "150/150 [==============================] - 0s - loss: 0.0653 - acc: 0.9800     \n",
      "Epoch 415/500\n",
      "150/150 [==============================] - 0s - loss: 0.0666 - acc: 0.9800     \n",
      "Epoch 416/500\n",
      "150/150 [==============================] - 0s - loss: 0.0655 - acc: 0.9800     \n",
      "Epoch 417/500\n",
      "150/150 [==============================] - 0s - loss: 0.0685 - acc: 0.9667     \n",
      "Epoch 418/500\n",
      "150/150 [==============================] - 0s - loss: 0.0654 - acc: 0.9733     \n",
      "Epoch 419/500\n",
      "150/150 [==============================] - 0s - loss: 0.0675 - acc: 0.9733     \n",
      "Epoch 420/500\n",
      "150/150 [==============================] - 0s - loss: 0.0658 - acc: 0.9800     \n",
      "Epoch 421/500\n",
      "150/150 [==============================] - 0s - loss: 0.0651 - acc: 0.9800     \n",
      "Epoch 422/500\n",
      "150/150 [==============================] - 0s - loss: 0.0656 - acc: 0.9667     \n",
      "Epoch 423/500\n",
      "150/150 [==============================] - 0s - loss: 0.0650 - acc: 0.9667     \n",
      "Epoch 424/500\n",
      "150/150 [==============================] - 0s - loss: 0.0648 - acc: 0.9733     \n",
      "Epoch 425/500\n",
      "150/150 [==============================] - 0s - loss: 0.0650 - acc: 0.9733     \n",
      "Epoch 426/500\n",
      "150/150 [==============================] - 0s - loss: 0.0644 - acc: 0.9800     \n",
      "Epoch 427/500\n",
      "150/150 [==============================] - 0s - loss: 0.0647 - acc: 0.9667     \n",
      "Epoch 428/500\n",
      "150/150 [==============================] - 0s - loss: 0.0643 - acc: 0.9667     \n",
      "Epoch 429/500\n",
      "150/150 [==============================] - 0s - loss: 0.0645 - acc: 0.9733     \n",
      "Epoch 430/500\n",
      "150/150 [==============================] - 0s - loss: 0.0640 - acc: 0.9800     \n",
      "Epoch 431/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s - loss: 0.0647 - acc: 0.9800     \n",
      "Epoch 432/500\n",
      "150/150 [==============================] - 0s - loss: 0.0649 - acc: 0.9733     \n",
      "Epoch 433/500\n",
      "150/150 [==============================] - 0s - loss: 0.0639 - acc: 0.9667     \n",
      "Epoch 434/500\n",
      "150/150 [==============================] - 0s - loss: 0.0638 - acc: 0.9667     \n",
      "Epoch 435/500\n",
      "150/150 [==============================] - 0s - loss: 0.0636 - acc: 0.9733     \n",
      "Epoch 436/500\n",
      "150/150 [==============================] - 0s - loss: 0.0648 - acc: 0.9800     \n",
      "Epoch 437/500\n",
      "150/150 [==============================] - 0s - loss: 0.0640 - acc: 0.9800     \n",
      "Epoch 438/500\n",
      "150/150 [==============================] - 0s - loss: 0.0635 - acc: 0.9800     \n",
      "Epoch 439/500\n",
      "150/150 [==============================] - 0s - loss: 0.0635 - acc: 0.9733     \n",
      "Epoch 440/500\n",
      "150/150 [==============================] - 0s - loss: 0.0635 - acc: 0.9667     \n",
      "Epoch 441/500\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0511 - acc: 0.968 - 0s - loss: 0.0638 - acc: 0.9667     \n",
      "Epoch 442/500\n",
      "150/150 [==============================] - 0s - loss: 0.0642 - acc: 0.9733     \n",
      "Epoch 443/500\n",
      "150/150 [==============================] - 0s - loss: 0.0630 - acc: 0.9800     \n",
      "Epoch 444/500\n",
      "150/150 [==============================] - 0s - loss: 0.0630 - acc: 0.9733     \n",
      "Epoch 445/500\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0584 - acc: 0.968 - 0s - loss: 0.0629 - acc: 0.9733     \n",
      "Epoch 446/500\n",
      "150/150 [==============================] - 0s - loss: 0.0654 - acc: 0.9667     \n",
      "Epoch 447/500\n",
      "150/150 [==============================] - 0s - loss: 0.0624 - acc: 0.9667     \n",
      "Epoch 448/500\n",
      "150/150 [==============================] - 0s - loss: 0.0617 - acc: 0.9800     \n",
      "Epoch 449/500\n",
      "150/150 [==============================] - 0s - loss: 0.0643 - acc: 0.9867     \n",
      "Epoch 450/500\n",
      "150/150 [==============================] - 0s - loss: 0.0641 - acc: 0.9867     \n",
      "Epoch 451/500\n",
      "150/150 [==============================] - 0s - loss: 0.0629 - acc: 0.9800     \n",
      "Epoch 452/500\n",
      "150/150 [==============================] - 0s - loss: 0.0631 - acc: 0.9667     \n",
      "Epoch 453/500\n",
      "150/150 [==============================] - 0s - loss: 0.0628 - acc: 0.9667     \n",
      "Epoch 454/500\n",
      "150/150 [==============================] - 0s - loss: 0.0624 - acc: 0.9800     \n",
      "Epoch 455/500\n",
      "150/150 [==============================] - 0s - loss: 0.0625 - acc: 0.9800     \n",
      "Epoch 456/500\n",
      "150/150 [==============================] - 0s - loss: 0.0628 - acc: 0.9733     \n",
      "Epoch 457/500\n",
      "150/150 [==============================] - 0s - loss: 0.0623 - acc: 0.9800     \n",
      "Epoch 458/500\n",
      "150/150 [==============================] - 0s - loss: 0.0624 - acc: 0.9800     \n",
      "Epoch 459/500\n",
      "150/150 [==============================] - 0s - loss: 0.0621 - acc: 0.9800     \n",
      "Epoch 460/500\n",
      "150/150 [==============================] - 0s - loss: 0.0620 - acc: 0.9800     \n",
      "Epoch 461/500\n",
      "150/150 [==============================] - 0s - loss: 0.0619 - acc: 0.9733     \n",
      "Epoch 462/500\n",
      "150/150 [==============================] - 0s - loss: 0.0622 - acc: 0.9667     \n",
      "Epoch 463/500\n",
      "150/150 [==============================] - 0s - loss: 0.0617 - acc: 0.9667     \n",
      "Epoch 464/500\n",
      "150/150 [==============================] - 0s - loss: 0.0617 - acc: 0.9800     \n",
      "Epoch 465/500\n",
      "150/150 [==============================] - 0s - loss: 0.0613 - acc: 0.9800     \n",
      "Epoch 466/500\n",
      "150/150 [==============================] - 0s - loss: 0.0616 - acc: 0.9800     \n",
      "Epoch 467/500\n",
      "150/150 [==============================] - 0s - loss: 0.0636 - acc: 0.9667     \n",
      "Epoch 468/500\n",
      "150/150 [==============================] - 0s - loss: 0.0624 - acc: 0.9667     \n",
      "Epoch 469/500\n",
      "150/150 [==============================] - 0s - loss: 0.0624 - acc: 0.9667     \n",
      "Epoch 470/500\n",
      "150/150 [==============================] - 0s - loss: 0.0613 - acc: 0.9733     \n",
      "Epoch 471/500\n",
      "150/150 [==============================] - 0s - loss: 0.0612 - acc: 0.9800     \n",
      "Epoch 472/500\n",
      "150/150 [==============================] - 0s - loss: 0.0614 - acc: 0.9800     \n",
      "Epoch 473/500\n",
      "150/150 [==============================] - 0s - loss: 0.0609 - acc: 0.9667     \n",
      "Epoch 474/500\n",
      "150/150 [==============================] - 0s - loss: 0.0607 - acc: 0.9733     \n",
      "Epoch 475/500\n",
      "150/150 [==============================] - 0s - loss: 0.0610 - acc: 0.9800     \n",
      "Epoch 476/500\n",
      "150/150 [==============================] - 0s - loss: 0.0611 - acc: 0.9800     \n",
      "Epoch 477/500\n",
      "150/150 [==============================] - 0s - loss: 0.0606 - acc: 0.9800     \n",
      "Epoch 478/500\n",
      "150/150 [==============================] - 0s - loss: 0.0609 - acc: 0.9800     \n",
      "Epoch 479/500\n",
      "150/150 [==============================] - 0s - loss: 0.0607 - acc: 0.9800     \n",
      "Epoch 480/500\n",
      "150/150 [==============================] - 0s - loss: 0.0601 - acc: 0.9800     \n",
      "Epoch 481/500\n",
      "150/150 [==============================] - 0s - loss: 0.0604 - acc: 0.9667     \n",
      "Epoch 482/500\n",
      "150/150 [==============================] - 0s - loss: 0.0607 - acc: 0.9667     \n",
      "Epoch 483/500\n",
      "150/150 [==============================] - 0s - loss: 0.0613 - acc: 0.9667     \n",
      "Epoch 484/500\n",
      "150/150 [==============================] - 0s - loss: 0.0601 - acc: 0.9800     \n",
      "Epoch 485/500\n",
      "150/150 [==============================] - 0s - loss: 0.0600 - acc: 0.9733     \n",
      "Epoch 486/500\n",
      "150/150 [==============================] - 0s - loss: 0.0602 - acc: 0.9800     \n",
      "Epoch 487/500\n",
      "150/150 [==============================] - 0s - loss: 0.0602 - acc: 0.9800     \n",
      "Epoch 488/500\n",
      "150/150 [==============================] - 0s - loss: 0.0629 - acc: 0.9800     \n",
      "Epoch 489/500\n",
      "150/150 [==============================] - 0s - loss: 0.0599 - acc: 0.9800     \n",
      "Epoch 490/500\n",
      "150/150 [==============================] - 0s - loss: 0.0608 - acc: 0.9667     \n",
      "Epoch 491/500\n",
      "150/150 [==============================] - 0s - loss: 0.0603 - acc: 0.9667     \n",
      "Epoch 492/500\n",
      "150/150 [==============================] - 0s - loss: 0.0602 - acc: 0.9667     \n",
      "Epoch 493/500\n",
      "150/150 [==============================] - 0s - loss: 0.0595 - acc: 0.9733     \n",
      "Epoch 494/500\n",
      "150/150 [==============================] - 0s - loss: 0.0601 - acc: 0.9800     \n",
      "Epoch 495/500\n",
      "150/150 [==============================] - 0s - loss: 0.0598 - acc: 0.9800     \n",
      "Epoch 496/500\n",
      "150/150 [==============================] - 0s - loss: 0.0599 - acc: 0.9800     \n",
      "Epoch 497/500\n",
      "150/150 [==============================] - 0s - loss: 0.0607 - acc: 0.9867     \n",
      "Epoch 498/500\n",
      "150/150 [==============================] - 0s - loss: 0.0595 - acc: 0.9800     \n",
      "Epoch 499/500\n",
      "150/150 [==============================] - 0s - loss: 0.0595 - acc: 0.9667     \n",
      "Epoch 500/500\n",
      "150/150 [==============================] - 0s - loss: 0.0601 - acc: 0.9667     \n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from keras.utils import np_utils\n",
    "iris = load_iris()\n",
    "\n",
    "data_x = iris.data\n",
    "data_y = iris.target\n",
    "\n",
    "train_x = data_x\n",
    "train_y = np_utils.to_categorical(data_y, 3)\n",
    "\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=500,  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.40666666984558103,\n",
       " 0.36666666626930239,\n",
       " 0.48666666865348818,\n",
       " 0.59333333412806188,\n",
       " 0.57333333412806198,\n",
       " 0.36666666746139526,\n",
       " 0.33333333432674406,\n",
       " 0.53333333412806194,\n",
       " 0.43333333452542622,\n",
       " 0.33333333432674406]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0978845135370889,\n",
       " 1.0965927680333456,\n",
       " 1.095999108950297,\n",
       " 1.0960081624984741,\n",
       " 1.0938612429300945,\n",
       " 1.0927142111460368,\n",
       " 1.093885137240092,\n",
       " 1.0872859319051107,\n",
       " 1.0859903256098429,\n",
       " 1.0819818162918091]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xt8XHWd//HXZ2YyubdpLr23tLRpoVwLoZRLtahAYV1Q\ncRUUBWRF/YmrKysLv/WHLntR3BUvu6DLKouigIA3ZEWQm+VOUy6FtpSmpfdbmrRpkzSXyXx+f8x0\nDCVN0zYnJzPzfj4eeXTOOd/MfE4IeT++3+8532PujoiICEAk7AJERGT4UCiIiEiGQkFERDIUCiIi\nkqFQEBGRDIWCiIhkKBQk55jZGjN7X9h1BCGXz02GB4WCiIhkKBREhoiZxcKuQeRAFAqS08ys0My+\na2ab0l/fNbPC9LFqM3vQzHaaWbOZPWVmkfSxvzezjWa228xWmNl79/P+VWb2OzPbZWaLzOyfzezp\nXsfdzD5vZiuBlel93zOz9envWWxm83q1/7qZ3W9mv0h/9ktmdsI+H3uimS0xs5Z0u6LB/rlJ/lIo\nSK77B2AucCJwAjAH+Gr62DXABqAGGAP8X8DNbCZwNXCKu5cD5wJr9vP+twBtwFjgsvTXvj4AnArM\nSm8vStdTCdwF3LfPH/YLgft6Hf+NmRX0Ov4RYAEwFTgeuLz/H4HIwCkUJNd9HLjR3be5eyPwj8An\n0se6gXHAEe7e7e5PeWoxsB6gEJhlZgXuvsbdV+37xmYWBS4Cvubu7e6+DPhJHzV8w92b3X0PgLv/\nzN2b3D3h7t9Of9bMXu0Xu/v97t4N3AwUkQq2vb7v7pvcvRn4HamAERkUCgXJdeOBtb2216b3Afwb\n0AA8Ymarzew6AHdvAL4EfB3YZmb3mNl43qkGiAHre+1b30e7t+0zs78zs+Xp4Z+dwEiguq/27p4k\n1Zvp/flber1uB8r6+EyRQ6JQkFy3CTii1/bk9D7cfbe7X+PuRwIXAF/eO3fg7ne5+5np73Xgpj7e\nuxFIABN77ZvUR7vMUsTp+YNrSQ0BjXL3CqAFsL7eIz3HMXFvzSJBUyhIrrsb+KqZ1ZhZNXAD8DMA\nM3u/mU03MyP1h7kHSJrZTDN7T3pCugPYAyT3fWN37wF+BXzdzErM7Cjgkweop5xUkDQCMTO7ARix\nT5uTzexD6auVvgR0As8f0tmLHCSFguS6fwbqgSXAa8BL6X0AtcCjQCvwHHCruz9Baoz/m8B2UkM1\no4Hr9/P+V5Ma/tkC3EkqhDr7qedh4A/Am6SGsjp455DTb4GPAjtIzX98KD2/IBI400N2RAaPmd0E\njHX3vq5CGsj3fx2Y7u6XDmphIgOknoLIYTCzo8zseEuZA1wJ/DrsukQOle6wFDk85aSGjMYDW4Fv\nkxr+EclKGj4SEZEMDR+JiEhG1g0fVVdX+5QpU8IuQ0QkqyxevHi7u9ccqF3WhcKUKVOor68PuwwR\nkaxiZmsP3ErDRyIi0otCQUREMhQKIiKSoVAQEZEMhYKIiGQoFEREJEOhICIiGXkTCiu27Obbj6yg\nqbW/VY1FRPJb3oTCqsZW/uPxBhoVCiIi+5U3oRCPpk61K/GOB2iJiEha/oRCTKEgInIgCgUREcnI\nu1DoVCiIiOxX/oRCVKEgInIgeRMKhXuHj3oUCiIi+5NHoRAFNKcgItKfwELBzG43s21m9vp+jn/c\nzJaY2Wtm9qyZnRBULaCJZhGRgQiyp3AHsKCf428B73b344B/Am4LsJZeodAT5MeIiGS1wB7H6e4L\nzWxKP8ef7bX5PDAxqFqgVyhoTkFEZL+Gy5zClcBD+ztoZleZWb2Z1Tc2Nh7SB+iOZhGRAws9FMzs\nLFKh8Pf7a+Put7l7nbvX1dTUHNLnFEQNUCiIiPQnsOGjgTCz44EfAee5e1PAn0U8FqFTw0ciIvsV\nWk/BzCYDvwI+4e5vDsVnFkYj6imIiPQjsJ6Cmd0NzAeqzWwD8DWgAMDdfwjcAFQBt5oZQMLd64Kq\nB1KTzQoFEZH9C/Lqo0sOcPyvgb8O6vP7Eo9FtMyFiEg/Qp9oHkrqKYiI9C+/QkFzCiIi/cqvUIhF\ndPOaiEg/8i8U1FMQEdmvvAqFQoWCiEi/8ioUygpj7OroDrsMEZFhK69CYUJFMRt37gm7DBGRYSuv\nQmHiqBJ2dyT44K3P8NPn1oRdjojIsJNnoVAMwMvrdnLDb5fi7iFXJCIyvORVKIyvKH7b9tMN20Oq\nRERkeMqrUJgxppy6I0Zx55VzGD+yiGvvX8KX732F37y8MezSRESGhbwKheJ4lPs/dzrzamv4/iWz\nqSiJ86uXNnLNfa9y53NrNJwkInnPsu0PYV1dndfX1w/a++3u6Obqu17mT282ctbMGr714ROoKS8c\ntPcXERkOzGzxQFaizqueQl/Kiwq444pT+PpfzuKZVU0s+O5CXl63I+yyRERCkfehAKmnsl1+xlQe\n/MKZlBbGuOz2F1m6qSXsskREhpxCoZcZY8r5+V+fSllhjE/++EWaWjvDLklEZEgpFPYxqbKEH112\nCk1tXdz94rqwyxERGVIKhT7MGj+Cd82o4fZn1mitJBHJKwqF/fjKOTPZ0d7FtfctCbsUEZEho1DY\nj+MmjuRv3zeDPyzdwvLNu8IuR0RkSCgU+nHp3CMoiBq/XLwh7FJERIaEQqEflaVx3nPUaH7zyiYS\neoyniOQBhcIBXHTSRLa3drJwZWPYpYiIBC6wUDCz281sm5m9vp/jZmbfN7MGM1tiZicFVcvhOOuo\n0VSVxvnlYi2aJyK5L8iewh3Agn6OnwfUpr+uAn4QYC2HrCAa4S9PGM+jy7fS2pkIuxwRkUAFFgru\nvhBo7qfJhcBPPeV5oMLMxgVVz+F4//Hj6EwkeXTZ1rBLEREJVJhzChOA9b22N6T3DTsnTR7FuJFF\nPLhkU9iliIgEKismms3sKjOrN7P6xsahn/CNRIz3Hz+OP73ZyM72riH/fBGRoRJmKGwEJvXanpje\n9w7ufpu717l7XU1NzZAUt68LT5xAd4/z+9e2hPL5IiJDIcxQeAD4ZPoqpLlAi7tvDrGefh0zfgRH\nVpfyh6UKBRHJXbGg3tjM7gbmA9VmtgH4GlAA4O4/BH4PnA80AO3AFUHVMhjMjHfNqOGeRevoTPRQ\nGIuGXZKIyKALLBTc/ZIDHHfg80F9fhDOnF7NHc+uYfHaHZw+rTrsckREBl1WTDQPF3OnVRGNGM80\nbA+7FBGRQCgUDkJZYYzZkyp4eqVCQURyk0LhIJ1ZW82SjS26NFVEcpJC4SDNq63GHZ5b1RR2KSIi\ng06hcJCOn1hBWWGMpzSvICI5SKFwkAqiEeYeWaV5BRHJSQqFQzCvtpp1ze2sa2oPuxQRkUGlUDgE\nZ0xP3aPwtIaQRCTHKBQOwbSaUsaNLOLpBj2NTURyi0LhEJgZZ0yv5tlVTfQkPexyREQGjULhEM2r\nrWZnezdLN7WEXYqIyKBRKByivWsfPaWrkEQkhygUDlFNeSFHjS3XOkgiklMUCodhXm019Wt2sKer\nJ+xSREQGhULhMJxZW0NXT5IX1zSHXYqIyKBQKByGOVMqicciPLliW9iliIgMCoXCYSiOR3lXbQ0P\nvbaFpC5NFZEcoFA4TOcdO5YtuzpYtnlX2KWIiBw2hcJhmjutCoDFa3eEXImIyOFTKBymCRXFjB9Z\nxItvabJZRLKfQmEQvGtGDU+u2KZLU0Uk6ykUBsEFJ4ynratHVyGJSNZTKAyCOVMr9TQ2EckJCoVB\nEEs/jU1LXohItgs0FMxsgZmtMLMGM7uuj+OTzewJM3vZzJaY2flB1hOkM6dXsbapnfXNehqbiGSv\nwELBzKLALcB5wCzgEjObtU+zrwL3uvts4GLg1qDqCdqZtTUA6i2ISFYLsqcwB2hw99Xu3gXcA1y4\nTxsHRqRfjwQ2BVhPoKbVlDJ2RJHmFUQkqwUZChOA9b22N6T39fZ14FIz2wD8HvhCX29kZleZWb2Z\n1Tc2Ds9HYGaextawXUteiEjWCnui+RLgDnefCJwP3Glm76jJ3W9z9zp3r6upqRnyIgfqzNoqdrR3\n87qexiYiWSrIUNgITOq1PTG9r7crgXsB3P05oAioDrCmQM2fMZpoxHhk6dawSxEROSRBhsIioNbM\npppZnNRE8gP7tFkHvBfAzI4mFQrDc3xoAEaVxjllyigeXa5QEJHsFFgouHsCuBp4GFhO6iqjpWZ2\no5ldkG52DfBpM3sVuBu43N2zekB+/szRvLFlN1t3dYRdiojIQYsF+ebu/ntSE8i9993Q6/Uy4Iwg\naxhq82qr+eZD8NTK7Xz45IlhlyMiclDCnmjOOUePHUF1WSEL38zaUTARyWMKhUEWiRjzaqt5umE7\nPbo0VUSyjEIhAPNn1tDc1sUr6/XgHRHJLgqFAJx11GgKoro0VUSyj0IhACOKCph7ZBUPL91Cll9M\nJSJ5RqEQkHOOGcuapnYatrWGXYqIyIApFAJy9tFjAHhkmYaQRCR7KBQCMnZkESdMquCRpVvCLkVE\nZMAUCgE6Z9YYXt3QwuaWPWGXIiIyIAqFAJ17TGoI6VENIYlIllAoBGhaTRlHVpdqXkFEsoZCIUBm\nxtnHjOG5VU207OkOuxwRkQNSKATsnFljSSSdJ1dsC7sUEZEDUigEbPakCqrLCjWEJCJZQaEQsEjE\nOHvWGJ58YxudiZ6wyxER6ZdCYQicc8wY2rp6eHZVU9iliIj064ChYGZfMLNRQ1FMrjp9WhWl8agW\nyBORYW8gPYUxwCIzu9fMFpiZBV1UrimMRZl/1Gj+uGwrST1jQUSGsQOGgrt/FagFfgxcDqw0s381\ns2kB15ZTzpk1hu2tnby8fmfYpYiI7NeA5hQ8tf7zlvRXAhgF3G9m3wqwtpyy9xkLDy7ZFHYpIiL7\nNZA5hS+a2WLgW8AzwHHu/jngZOCigOvLGSOKCjhn1lh+/fJGOrp1FZKIDE8D6SlUAh9y93Pd/T53\n7wZw9yTw/kCryzEXz5nEzvZuHtbKqSIyTA1kTuFr7r52P8eWD35JueuMadVMqizmF4vWh12KiEif\ndJ/CEIpEjI/WTeLZVU2sbWoLuxwRkXcINBTSl7CuMLMGM7tuP20+YmbLzGypmd0VZD3DwV/VTSIa\nMe5Rb0FEhqHAQsHMosAtwHnALOASM5u1T5ta4HrgDHc/BvhSUPUMF2NGFHHWzNHcV7+B7p5k2OWI\niLxNkD2FOUCDu6929y7gHuDCfdp8GrjF3XcAuHteLCV6yZxJbG/t5LHleXG6IpJFggyFCUDvMZIN\n6X29zQBmmNkzZva8mS3o643M7Cozqzez+sbGxoDKHTrvnlHDmBGF3LNoXdiliIi8TdgTzTFSd0vP\nBy4B/tvMKvZt5O63uXudu9fV1NQMcYmDLxaN8JG6SfzpzUbWN7eHXY6ISEaQobARmNRre2J6X28b\ngAfcvdvd3wLeJBUSOe9jp04masaPn34r7FJERDKCDIVFQK2ZTTWzOHAx8MA+bX5DqpeAmVWTGk5a\nHWBNw8a4kcVccOJ4frFoPTvausIuR0QECDAU3D0BXA08DCwH7nX3pWZ2o5ldkG72MNBkZsuAJ4Cv\nuHvePHTgM++axp7uHm5/Rr0FERkeLLXWXfaoq6vz+vr6sMsYNP/n54v504pGFl57FlVlhWGXIyI5\nyswWu3vdgdqFPdGc97589gz2dPfwgydXhV2KiIhCIWzTR5dz0UkT+elza3UlkoiETqEwDHz5nBlE\nIvDvj6wIuxQRyXMKhWFg3MhiPnXGVH77yiZe39gSdjkikscUCsPEZ+dPo6KkgG8+9AbZNvkvIrlD\noTBMjCgq4G/eU8vTDdv53ZLNYZcjInlKoTCMXHb6FE6YVMHXfvs621s7wy5HRPKQQmEYiUaMf//w\n8bR19nD9r14jmdQwkogMLYXCMFM7ppxrF8zkj8u28l8L82LFDxEZRhQKw9CVZ07l3GPG8P3HVrJx\n556wyxGRPKJQGIbMjP/3/lk4zg2/eV1XI4nIkFEoDFMTR5Vw7blH8dgb27S8togMGYXCMHbFGVM4\n95gxfPOhN1i8tjnsckQkDygUhjEz41sfPoHxFcV85s7FWhtJRAKnUBjmRhYXcPvlp9CVSPKpOxax\nq6M77JJEJIcpFLLA9NFl/PDSk3lrexuf//lLdPckwy5JRHKUQiFLnD69mn/94HE8tXI7N/x2qa5I\nEpFAxMIuQAbuI6dM4q2mNn7w5CqOHlfOJ0+bEnZJIpJj1FPIMl85ZybvPWo0N/5uGc82bA+7HBHJ\nMQqFLBOJGDd/9ESmVpfyqZ8s4hkFg4gMIoVCFhpZXMDdV81lSlUpn7pjEa+s3xl2SSKSIxQKWaq6\nrJC7Pj2X6rJCrr7rJVradamqiBw+hUIWqyyN858fm82Wlg4u+uGzbGnpCLskEclyCoUsN3vyKH76\nqTlsaengsz9bTI+ewSAihyHQUDCzBWa2wswazOy6ftpdZGZuZnVB1pOrTp9ezb988FheWb+T6365\nRMEgIocssPsUzCwK3AKcDWwAFpnZA+6+bJ925cAXgReCqiUfXHDCeFY3tvG9x1ZiBjdeeCxFBdGw\nyxKRLBNkT2EO0ODuq929C7gHuLCPdv8E3ARoQPwwmBl/e/YMPjd/GvfWb+Di256nK6HlMETk4AQZ\nChOA9b22N6T3ZZjZScAkd//f/t7IzK4ys3ozq29sbBz8SnPItefO5KaLjuOV9Tv5xkPLwy5HRLJM\naBPNZhYBbgauOVBbd7/N3evcva6mpib44rKYmfHRUyZzxRlT+J9n1vDAq5vCLklEskiQobARmNRr\ne2J6317lwLHAk2a2BpgLPKDJ5sFx/XlHc8qUUfztL17hyRXbwi5HRLJEkKGwCKg1s6lmFgcuBh7Y\ne9DdW9y92t2nuPsU4HngAnevD7CmvBGPRfifK+Ywc0w5n//5S7y8bkfYJYlIFggsFNw9AVwNPAws\nB+5196VmdqOZXRDU58qflRXGuP3yU6gsi3Ppj15g+eZdYZckIsOcZdu6/HV1dV5fr87EwdjS0sEF\n//k0nYkkv/zcaUwfXR52SSIyxMxssbsfcHhedzTngbEji7j/s6cTixhX3LGIhm2tYZckIsOUQiFP\nTK4q4UeX1bGnq4dP/PgFNu7cE3ZJIjIMKRTySGqdpFNp7UjwyR+/QHNbV9glicgwo1DIM7PGj+BH\nl9WxYccerrhjEW2dibBLEpFhRKGQh049sor//NhJvL6xhSt/soj2LgWDiKQoFPLU2bPG8J2PnsiL\nbzXzqTsUDCKSolDIYxecMF7BICJvo1DIcxeeOEHBICIZCgVRMIhIhkJBgFQw3PyRVDB8/Ecv0Kqr\nkkTykkJBMj4wewK3fvxklmxo4aqf1tPR3RN2SSIyxBQK8jYLjh3Lv//V8Ty3uolP3bFIPQaRPKNQ\nkHf44OyJ3PyRE3h+dRPnfW8h65rawy5JRIaIQkH69MHZE7n3M6fR0t7Ned9byLOrtoddkogMAYWC\n7FfdlEoe/MI8xlcU8+mf1POSHtQjkvMUCtKvyVUl3HnlqVSXF/Kx/36eR5ZuCbskEQmQQkEOaOzI\nIn75udM5auwIPvOzxdzxzFthlyQiAVEoyIBUlxVy96fncvbRY/j675bx1d+8RmdCl6yK5BqFggxY\ncTzKDy49mc+860h+9vw6/uqHz7G+WVcmieQShYIclGjEuP78o/nhpSfzVmMb5353Ifcv3hB2WSIy\nSBQKckgWHDuW//2beRw7YSR//8sl/NvDb+gOaJEcoFCQQza5qoTbLz+FD5w4gVueWMVffP8pXlm/\nM+yyROQwKBTksJQVxvj2R07gzivnsL21iw/c8gzf+sMbJJMedmkicggUCjIo5tXW8MTfzefiUyZx\n65Or+PiPXmB1Y2vYZYnIQQo0FMxsgZmtMLMGM7uuj+NfNrNlZrbEzB4zsyOCrEeCVVka5xsfOo5v\nfOg4Xt/UwoLvPsX3Hl2pS1dFskhgoWBmUeAW4DxgFnCJmc3ap9nLQJ27Hw/cD3wrqHpkaJgZl8yZ\nzGPXvJtzjx3Ldx59k/O+9xTPr24KuzQRGYAgewpzgAZ3X+3uXcA9wIW9G7j7E+6+90L354GJAdYj\nQ2h0eRH/ccls7rjiFLp7klx82/N85b5X2dLSEXZpItKPIENhArC+1/aG9L79uRJ4qK8DZnaVmdWb\nWX1jY+MglihBmz9zNI986d189t3T+NXLGznzpse58XfL2LRzT9iliUgfhsVEs5ldCtQB/9bXcXe/\nzd3r3L2upqZmaIuTw1Ycj3LdeUfx+DXv5rzjxvGT59bwvpv/xA//tEr3NogMM0GGwkZgUq/tiel9\nb2Nm7wP+AbjA3TsDrEdCdkRVKf9xyWye/Lv5nD6tmm8+9AZn3vQ4P3hyFbs7usMuT0QAcw/menIz\niwFvAu8lFQaLgI+5+9JebWaTmmBe4O4rB/K+dXV1Xl9fH0DFMtSeX93ErU+uYuGbjZQXxbj89Clc\nccZUKkvjYZcmknPMbLG71x2wXVChkC7ifOC7QBS43d3/xcxuBOrd/QEzexQ4Dtic/pZ17n5Bf++p\nUMg9r21o4dYnG/jD0i0UxaK8//hxfPSUSZw0eRSRiIVdnkhOGBahEASFQu5q2NbKbQtX8dBrW9jd\nmaB2dBkLjh3LxXMmM6GiOOzyRLKaQkGy1q6Obh56bTP31W/gpXU7MDNqR5fxwdkT+MRpR9C4u5PJ\nlSWYqRchMlAKBckJG3a084MnV7F88y5eWvfnxfY+PW8qnz9rOhUlmn8QGQiFguSc51Y18f3HVvJc\n+u7owliED5w4gfOOG8vcI6soKoiGXKHI8DXQUIgNRTEig+G0aVWcNq0KgOWbd/HT59by65c38Iv6\n9cRjEU6dWsn5x41jztRKjqwu1fCSyCFQT0GyWkd3Dy+81czCNxt5dPlW1jalVk0ZVVLAnKmVHDV2\nBLMnV3Dq1CqK4+pJSP7S8JHkHXdnVWMrL63dyaI1zbzwVjPr0s+QjhicfMQo5s8czfTRZZw0eRQ1\n5YUhVywydBQKIqR6Eg8u2czqxlYWrmzk9Y27MscmVBQzr7aaY8aP4KhxI5hQUczI4gJKCzWqKrlH\noSDSh+a2LtY0tfHS2h08u6qJl9btYGf7n5fYKIxFqCqNs6O9m7opo/jwyROpm1Kp+yQk6ykURAbA\n3dnU0sGbW3azrrmdFVt3s21XJ48u3/q2duNGFjFr3AiqyuJMqylj+ugyptWUMamyhKjuupYsoKuP\nRAbAzJhQUfyOnkBbZ4J4LMIbm3ezeG0zi9ftZOXW3by6oYV76zdk2sVjESqKCyiOR5k9qYLJVaWM\nLi+koqSAmrJCjp9YoQluySrqKYgcpJb2bhoaW1m1rZVVja207OlmR3sXi9fupKmtk33/l6oqjTO+\nopjR5YU4UF0WZ15tDZWlcVY3tjJtdBnHTRhJWWGMRNIpiA6LFe0lx2j4SCQEiZ4k21u72Lmniw3N\ne1i+eRebWjrYtHMPjbs76ejuYV1zO4nkO/+/Ky6I0t2TZF5tNWbG9NFltHYm2N2R4C+OG8uYEUUA\nTBxVQnlRjMJYRPdiyIApFESGqd0d3Wxu6WD77k6K41E2t3SwvrmdzS0d7GjvYsWW3bhDQ2MrRbEI\niaTTmUi+433MUkGSdGd8RTHlhTEqS+NUlRVSVRZnRFEBlaVxiguiRCJGQcSYUl3K+JHFlBfFiESM\nvf//Jx3NjeQ4zSmIDFPlRQWUFxUwY0w5ALP3064rkSRikEg6yzfvYkd7F8lkaj2otq4eOrp72NPV\nw57uHlY1thKPRWls7eSNLbtpau2iq+edQbJXxGBkcQEOtHYkKIhGmFxZwsjiAiZWFjOiqCATOpWl\ncWIRo7KsEHenqrSQpDste7o5elw5ETOqSgvpTiZZ19zOseNHEo9pCCxbKRREhqm9f1hjUZg9edRB\nfa97qnfRuLuT7p4kSU/ds7F6exuNuzvZ2d7FzvZuOhM9lBUWsKO9i9bOBI27O3lhdTO7Orrx9Pf0\nNdTVn6KCCCXxGKNKChhVEicaMQqiEaIRo7woRmk8RtKdeCxCSTxKRUmc9q4EJfEYrZ0JJo4qpiQe\npbywgKKCKIUFEeLRSK9/oxTGIsRjEQpjEToTScoLY5mhtGTSMUtdRNDU2sn21i7GVRQxoqjgoM4j\nXykURHKQmVFUEGVSZcnb9h87YeRBvU8y6ezq6KYn6Wxv7SIaIf2vURSLsnzLLqJmNLd1ZUJsdWMr\niaSzdVcn7V0JEknP/LuuuZ32rgQRM7oSSVo7E28bGjPjHRP1AxFPT87HYxFaOxNUlxUSjcDWXX9+\nwu/MMeVEIkZVaZySeJR4LBVUUTP2dPcwqbKErbs6KCuMMXZEEQWxCAXRCLGI8dyqJqZUl9KTTBKJ\nGFOrSjNBB1ASj1JWGKPHndLCGCXxKC++1UxFSZwjq0sZWVxALGrEIqlgK4ilfn57unto60owuryI\n9q4EC9/czrzaakri0T5DbigoFERkvyIRyyxPXlWWWhZk+ug/Hz9u4sGFTF86untSIdGTGi7b0d5N\nVyLJrj3ddCaSdCWSdCZ63vG6szv1Oh6L0NTWBaSG3MoLY6xqbCPpTnFBlO1tXYwdUcj21lSb5rYu\ntu3uIJF0unuS9PQ40ajx+BvbKCuM0d2TZFdHYr/1FkSN7p7Dn4uNRSzTCyuNpwJib6esMBZhVEmc\ntq4E3T3J1LyQGZ847Qi+9L4Zh/3Z/dYV6LuLiBzA3iXP9/Y0SuLh/lly90xgdPc4XYkkpYVRVje2\nMaKogOryODvTwdXjjgHtXT20dqZ6QG2dCXZ3JphWUwrA6sY29nT30JN0Eun37O5JsqO9m4qSAgzY\nsquDgmgEs1SvpzORZHtrZ2bIa3dHgsKCCMeOP/wQPhCFgohIL2ZGQdTecb9I76G3gwmuY4bgD/lg\n0iUCIiKSoVAQEZEMhYKIiGQoFEREJEOhICIiGYGGgpktMLMVZtZgZtf1cbzQzH6RPv6CmU0Jsh4R\nEelfYKFgZlHgFuA8YBZwiZnN2qfZlcAOd58OfAe4Kah6RETkwILsKcwBGtx9tbt3AfcAF+7T5kLg\nJ+nX9wNxw6mzAAAE50lEQVTvNa0FLCISmiBvXpsArO+1vQE4dX9t3D1hZi1AFbC9dyMzuwq4Kr3Z\namYrDrGm6n3fOw/onPODzjk/HM45HzGQRllxR7O73wbcdrjvY2b1A1lPPJfonPODzjk/DMU5Bzl8\ntBGY1Gt7Ynpfn23MLAaMBJoCrElERPoRZCgsAmrNbKqZxYGLgQf2afMAcFn69YeBxz3bHgUnIpJD\nAhs+Ss8RXA08DESB2919qZndCNS7+wPAj4E7zawBaCYVHEE67CGoLKRzzg865/wQ+Dln3TOaRUQk\nOLqjWUREMhQKIiKSkTehcKAlN7KVmd1uZtvM7PVe+yrN7I9mtjL976j0fjOz76d/BkvM7KTwKj90\nZjbJzJ4ws2VmttTMvpjen7PnbWZFZvaimb2aPud/TO+fml4ipiG9ZEw8vT8nlpAxs6iZvWxmD6a3\nc/p8AcxsjZm9ZmavmFl9et+Q/W7nRSgMcMmNbHUHsGCffdcBj7l7LfBYehtS51+b/roK+MEQ1TjY\nEsA17j4LmAt8Pv3fM5fPuxN4j7ufAJwILDCzuaSWhvlOeqmYHaSWjoHcWULmi8DyXtu5fr57neXu\nJ/a6J2HofrfdPee/gNOAh3ttXw9cH3Zdg3h+U4DXe22vAMalX48DVqRf/xdwSV/tsvkL+C1wdr6c\nN1ACvERqhYDtQCy9P/N7Tuqqv9PSr2PpdhZ27Qd5nhPTfwDfAzwIWC6fb6/zXgNU77NvyH6386Kn\nQN9LbkwIqZahMMbdN6dfbwHGpF/n3M8hPUwwG3iBHD/v9FDKK8A24I/AKmCnuyfSTXqf19uWkAH2\nLiGTTb4LXAsk09tV5Pb57uXAI2a2OL3EDwzh73ZWLHMhh87d3cxy8rpjMysDfgl8yd139V5LMRfP\n2917gBPNrAL4NXBUyCUFxszeD2xz98VmNj/seobYme6+0cxGA380szd6Hwz6dztfegoDWXIjl2w1\ns3EA6X+3pffnzM/BzApIBcLP3f1X6d05f94A7r4TeILU8ElFeokYePt5ZfsSMmcAF5jZGlIrLL8H\n+B65e74Z7r4x/e82UuE/hyH83c6XUBjIkhu5pPfyIZeRGnPfu/+T6SsW5gItvbqkWcNSXYIfA8vd\n/eZeh3L2vM2sJt1DwMyKSc2hLCcVDh9ON9v3nLN2CRl3v97dJ7r7FFL/vz7u7h8nR893LzMrNbPy\nva+Bc4DXGcrf7bAnVYZw8uZ84E1S47D/EHY9g3hedwObgW5S44lXkhpLfQxYCTwKVKbbGqmrsFYB\nrwF1Ydd/iOd8Jqlx1yXAK+mv83P5vIHjgZfT5/w6cEN6/5HAi0ADcB9QmN5flN5uSB8/MuxzOIxz\nnw88mA/nmz6/V9NfS/f+rRrK320tcyEiIhn5MnwkIiIDoFAQEZEMhYKIiGQoFEREJEOhICIiGQoF\nERHJUCiIiEiGQkHkMJnZKem17IvSd6QuNbNjw65L5FDo5jWRQWBm/0zqrtpiYIO7fyPkkkQOiUJB\nZBCk19RaBHQAp3tqRVORrKPhI5HBUQWUAeWkegwiWUk9BZFBYGYPkFrieSqpJ19dHXJJIodED9kR\nOUxm9kmg293vSj8P/Fkze4+7Px52bSIHSz0FERHJ0JyCiIhkKBRERCRDoSAiIhkKBRERyVAoiIhI\nhkJBREQyFAoiIpLx/wHrYz9FAR73PQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xf18d668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('loss graph')\n",
    "\n",
    "plt.plot(range(len(history.history['loss'])), history.history['loss'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEclSUBARkSwFBRERyfr/cI2pPKPv1eQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x103ef940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('acc graph')\n",
    "\n",
    "plt.plot(range(len(history.history['acc'])), history.history['acc'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1.4 Visualize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"483pt\" viewBox=\"0.00 0.00 174.00 483.00\" width=\"174pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 479)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-479 170,-479 170,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 159868296 -->\n",
       "<g class=\"node\" id=\"node1\"><title>159868296</title>\n",
       "<polygon fill=\"none\" points=\"0,-438.5 0,-474.5 166,-474.5 166,-438.5 0,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83\" y=\"-452.8\">dense_1_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 159867624 -->\n",
       "<g class=\"node\" id=\"node2\"><title>159867624</title>\n",
       "<polygon fill=\"none\" points=\"31,-365.5 31,-401.5 135,-401.5 135,-365.5 31,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83\" y=\"-379.8\">dense_1: Dense</text>\n",
       "</g>\n",
       "<!-- 159868296&#45;&gt;159867624 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>159868296-&gt;159867624</title>\n",
       "<path d=\"M83,-438.313C83,-430.289 83,-420.547 83,-411.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"86.5001,-411.529 83,-401.529 79.5001,-411.529 86.5001,-411.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 160014968 -->\n",
       "<g class=\"node\" id=\"node3\"><title>160014968</title>\n",
       "<polygon fill=\"none\" points=\"9,-292.5 9,-328.5 157,-328.5 157,-292.5 9,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83\" y=\"-306.8\">activation_1: Activation</text>\n",
       "</g>\n",
       "<!-- 159867624&#45;&gt;160014968 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>159867624-&gt;160014968</title>\n",
       "<path d=\"M83,-365.313C83,-357.289 83,-347.547 83,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"86.5001,-338.529 83,-328.529 79.5001,-338.529 86.5001,-338.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 160018384 -->\n",
       "<g class=\"node\" id=\"node4\"><title>160018384</title>\n",
       "<polygon fill=\"none\" points=\"31,-219.5 31,-255.5 135,-255.5 135,-219.5 31,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83\" y=\"-233.8\">dense_2: Dense</text>\n",
       "</g>\n",
       "<!-- 160014968&#45;&gt;160018384 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>160014968-&gt;160018384</title>\n",
       "<path d=\"M83,-292.313C83,-284.289 83,-274.547 83,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"86.5001,-265.529 83,-255.529 79.5001,-265.529 86.5001,-265.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 159867904 -->\n",
       "<g class=\"node\" id=\"node5\"><title>159867904</title>\n",
       "<polygon fill=\"none\" points=\"9,-146.5 9,-182.5 157,-182.5 157,-146.5 9,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83\" y=\"-160.8\">activation_2: Activation</text>\n",
       "</g>\n",
       "<!-- 160018384&#45;&gt;159867904 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>160018384-&gt;159867904</title>\n",
       "<path d=\"M83,-219.313C83,-211.289 83,-201.547 83,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"86.5001,-192.529 83,-182.529 79.5001,-192.529 86.5001,-192.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 159868856 -->\n",
       "<g class=\"node\" id=\"node6\"><title>159868856</title>\n",
       "<polygon fill=\"none\" points=\"31,-73.5 31,-109.5 135,-109.5 135,-73.5 31,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83\" y=\"-87.8\">dense_3: Dense</text>\n",
       "</g>\n",
       "<!-- 159867904&#45;&gt;159868856 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>159867904-&gt;159868856</title>\n",
       "<path d=\"M83,-146.313C83,-138.289 83,-128.547 83,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"86.5001,-119.529 83,-109.529 79.5001,-119.529 86.5001,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 160078536 -->\n",
       "<g class=\"node\" id=\"node7\"><title>160078536</title>\n",
       "<polygon fill=\"none\" points=\"9,-0.5 9,-36.5 157,-36.5 157,-0.5 9,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83\" y=\"-14.8\">activation_3: Activation</text>\n",
       "</g>\n",
       "<!-- 159868856&#45;&gt;160078536 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>159868856-&gt;160078536</title>\n",
       "<path d=\"M83,-73.3129C83,-65.2895 83,-55.5475 83,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"86.5001,-46.5288 83,-36.5288 79.5001,-46.5289 86.5001,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. More about keras\n",
    "\n",
    "* activation: https://keras.io/activations/, modify activation function\n",
    "* compile: https://keras.io/models/sequential/\n",
    "   * loss: https://keras.io/losses/\n",
    "* add more layers\n",
    "* train & valid\n",
    "* training data modified to MNIST\n",
    "* model persist: https://keras.io/models/about-keras-models/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_x = iris.data\n",
    "data_y = np_utils.to_categorical(iris.target, 3)\n",
    "\n",
    "\n",
    "\n",
    "train_x = data_x\n",
    "train_y = data_y\n",
    "\n",
    "valid_x = data_x[130:]\n",
    "valid_y = data_y[130:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 150 samples, validate on 20 samples\n",
      "Epoch 1/10\n",
      "150/150 [==============================] - 0s - loss: 0.7555 - acc: 0.6667 - val_loss: 1.2751 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 0s - loss: 0.7235 - acc: 0.6667 - val_loss: 1.0430 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 0s - loss: 0.6879 - acc: 0.6667 - val_loss: 0.8553 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 0s - loss: 0.6848 - acc: 0.6600 - val_loss: 0.7016 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 0s - loss: 0.6755 - acc: 0.6667 - val_loss: 0.6647 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 0s - loss: 0.6648 - acc: 0.6667 - val_loss: 0.7185 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 0s - loss: 0.6518 - acc: 0.6667 - val_loss: 0.7684 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 0s - loss: 0.6444 - acc: 0.6800 - val_loss: 0.8084 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 0s - loss: 0.6355 - acc: 0.6667 - val_loss: 0.8039 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 0s - loss: 0.6286 - acc: 0.7467 - val_loss: 0.7774 - val_acc: 0.9500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xbc54f60>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, epochs=10,  verbose=1, validation_data=(valid_x, valid_y) )#, validation_split=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 0s - loss: 0.3724 - acc: 0.8333 - val_loss: 1.1027 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 0s - loss: 0.3704 - acc: 0.8333 - val_loss: 1.1392 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 0s - loss: 0.3701 - acc: 0.8333 - val_loss: 1.1763 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 0s - loss: 0.3683 - acc: 0.8333 - val_loss: 1.1824 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 0s - loss: 0.3671 - acc: 0.8333 - val_loss: 1.1509 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 0s - loss: 0.3647 - acc: 0.8333 - val_loss: 1.1371 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 0s - loss: 0.3637 - acc: 0.8333 - val_loss: 1.1420 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 0s - loss: 0.3624 - acc: 0.8333 - val_loss: 1.1040 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 0s - loss: 0.3601 - acc: 0.8333 - val_loss: 1.0996 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 0s - loss: 0.3596 - acc: 0.8333 - val_loss: 1.1152 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xbc54c50>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, epochs=10,  verbose=1, validation_split=0.2 )#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 MNIST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from keras.utils import np_utils\n",
    "\n",
    "digit = load_digits()\n",
    "\n",
    "data_x = digit.data\n",
    "data_y = np_utils.to_categorical(digit.target, 10)\n",
    "\n",
    "train_x = data_x\n",
    "train_y = data_y\n",
    "\n",
    "data_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential() # 顺序模型\n",
    "\n",
    "# 输入层\n",
    "model.add(Dense(400, input_shape=(64,)))  # Dense就是常用的全连接层\n",
    "model.add(Activation('sigmoid')) # 激活函数\n",
    "\n",
    "# 隐层\n",
    "model.add(Dense(160))  # Dense就是常用的全连接层\n",
    "model.add(Activation('sigmoid')) # 激活函数\n",
    "\n",
    "# 输出层\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1437 samples, validate on 360 samples\n",
      "Epoch 1/10\n",
      "1437/1437 [==============================] - 0s - loss: 1.4335 - acc: 0.6910 - val_loss: 0.8681 - val_acc: 0.8278\n",
      "Epoch 2/10\n",
      "1437/1437 [==============================] - 0s - loss: 0.4860 - acc: 0.9304 - val_loss: 0.5292 - val_acc: 0.8750\n",
      "Epoch 3/10\n",
      "1437/1437 [==============================] - 0s - loss: 0.2547 - acc: 0.9589 - val_loss: 0.4040 - val_acc: 0.8861\n",
      "Epoch 4/10\n",
      "1437/1437 [==============================] - 0s - loss: 0.1673 - acc: 0.9798 - val_loss: 0.3525 - val_acc: 0.9028\n",
      "Epoch 5/10\n",
      "1437/1437 [==============================] - 0s - loss: 0.1190 - acc: 0.9847 - val_loss: 0.3150 - val_acc: 0.9139\n",
      "Epoch 6/10\n",
      "1437/1437 [==============================] - 0s - loss: 0.0880 - acc: 0.9916 - val_loss: 0.3036 - val_acc: 0.9083\n",
      "Epoch 7/10\n",
      "1437/1437 [==============================] - 0s - loss: 0.0712 - acc: 0.9930 - val_loss: 0.2956 - val_acc: 0.9111\n",
      "Epoch 8/10\n",
      "1437/1437 [==============================] - 0s - loss: 0.0572 - acc: 0.9951 - val_loss: 0.2742 - val_acc: 0.9000\n",
      "Epoch 9/10\n",
      "1437/1437 [==============================] - 0s - loss: 0.0473 - acc: 0.9958 - val_loss: 0.2750 - val_acc: 0.9167\n",
      "Epoch 10/10\n",
      "1437/1437 [==============================] - 0s - loss: 0.0377 - acc: 0.9965 - val_loss: 0.2545 - val_acc: 0.9167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xc6823d6908>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, epochs=10,  verbose=1, validation_split=0.2 )#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2.3 model persist and load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.save\n",
    "\n",
    "* the architecture of the model, allowing to re-create the model\n",
    "* the weights of the model\n",
    "* the training configuration (loss, optimizer)\n",
    "* the state of the optimizer, allowing to resume training exactly where you left off.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model2 = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model2.predict(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00366759,  0.40605679,  0.03928011,  0.28569439,  0.00639894,\n",
       "        0.002873  ,  0.00140929,  0.01577912,  0.07232288,  0.16651784], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[1500]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
